==================
CORE JAVA CONCEPTS
==================


Concurrency and Multithreading:
===============================

References:
Concepts by Jakob Jenkov: https://www.youtube.com/playlist?list=PLL8woMHwr36EDxjUoCzboZjedsnhLP1j4
in28Minutes: https://www.youtube.com/watch?v=905Emnqi5JM


Introduction:
=============

Single-Tasking (in early computers):
------------------------------------
  - One CPU/Computer can run only one program at a time.
  - If we want to work on another program/application, we need to close the current one and open the new one.

Multi-Tasking:
--------------
  - One CPU/Computer can run multiple programs at a time.
  - Done by switching the execution of one program at a time for a little time and then switch to the next.

Multi-Threading:
----------------
  - One CPU/Computer can run multiple programs at a time.
  - Acheived by running multiple threads inside single application.
  - For example: an application can download a file with one thread and playing music with another thread at the same time.

Multi-Threading in multiple CPU:
--------------------------------
  - Modern computers come with multiple CPUs in them or multiple Core within CPU.
  - Since there are multiple CPUs, at a given time multiple tasks can run in parallel.
  - It is possible for an application to run its task by one thread in one CPU and another thread in the other CPU.



Why Multi-Threading:
====================
Consider an application that need to perform many tasks. So at a particular time, if a thread A is responsible for I/O operation (file download and processing) when the file download is in progress, CPU can switch to another thread B to perform some other operation.



Multi-Threading issues:
=======================
Shared mutable state issues:
----------------------------
  - Missed signals
  - Invisible writes
  - Starvation
  - Slipped conditions
  - Congestion
  - Nested monitor lock
  - Deadlock
  - Race conditions


No shared mutable state concurrency:
------------------------------------
  - Seperate state concurrency
  - Functional parallelism
  - Parallel pipelines
  - etc.



Thread basics:
==============

Ways to create Threads:
-----------------------
1. By extending Thread class.

  public static class MyThread extends Thread {
    public void run() {
      System.out.println("MyThread running");
      System.out.println("MyThread finished");
    }
  }

  public class ThreadExample {
	public static void main(String[] args) {
	  MyThread myThread = new MyThread();
	  myThread.start();
	}
  }


2. By implementing Runnable interface

  public static class MyRunnable implements Runnable {
    public void run() {
	  System.out.println("MyRunnable running");
	  System.out.println("MyRunnable finished");
	}
  }

  public class ThreadExample {
	public static void main(String[] args) {
	  MyRunnable myRunnable = new MyRunnable();
	  Thread myThread = new Thread(myRunnable);
	  myThread.start();
	}
  }


3. By implementing Runnable interface with Anonymous class

  public class ThreadExample {
    
	public static void main(String[] args) {
	  Runnable myRunnable = new Runnable() {
	    public void run() {
	      System.out.println("MyRunnable running");
	      System.out.println("MyRunnable finished");
	    }
	  };
	  
	  Thread myThread = new Thread(myRunnable);
	  myThread.start();
	}
  }


4. By implementing Runnable interface using lambda expression

  public class ThreadExample {
    
	public static void main(String[] args) {
	  Runnable myRunnable = () -> {
	    System.out.println("MyRunnable running");
	    System.out.println("MyRunnable finished");
	  };
	  
	  Thread myThread = new Thread(myRunnable);
	  myThread.start();
	}
  }


Thread.currentThread(): Using this method, we can get the reference to currently executing thread.

Thread myThread = new Thread(myRunnable, "First_Thread"): To set a name for thread while creating it.


Different States of a Thread:
=============================
1. NEW – a newly created thread that has not yet started the execution
2. RUNNABLE – ready for execution but it's waiting for resource allocation
3. RUNNING - the thread is actually running
3. BLOCKED – waiting to acquire a monitor lock to enter or re-enter a synchronized block/method
4. WAITING – waiting for some other thread to perform a particular action without any time limit
5. TIMED_WAITING – waiting for some other thread to perform a specific action for a specified period
6. TERMINATED – has completed its execution


Thread Priorities:
==================
Threads can be given priority so that we can plan which thread to run before and which ones to run after.
Setting priority does not guarantee that it will in that order. 
Below are the variable that can be used while setting priority. 
  MIN_PRIORITY = 1
  NORM_PRIORITY = 5
  MAX_PRIORITY = 10
However, we can set any priority from 1-10 using int values.
thread1.setPriority(3);


Communication between threads:
==============================
Thread.sleep():
---------------
sleep() is a method which is used to pause the process for few seconds or the time we want to.
sleep() doesn't releases the lock or monitor while waiting.

thread.yeild():
---------------
Theoretically, to ‘yield’ means to let go, to give up, to surrender.
A yielding thread tells the virtual machine that it’s willing to let other threads be scheduled in its place. 
This indicates that it’s not doing something too critical. 
Note that it’s only a hint, though, and not guaranteed to have any effect at all.

wait(), notify(), notifyAll():
------------------------------
In case of wait() method, thread goes in waiting state and it won't come back automatically until we call the notify() or notifyAll().
wait() releases the lock or monitor.

thread.join():
--------------
For example, if we want task1 and task2 to complete before task3 starts, we can do as follows.
t1Obj.join();
t2Thread.join();


Daemon Threads:
===============
It is a service provider thread that provides services to the user threads.
Its life depends on the mercy of user threads i.e. when all the user threads dies, JVM terminates this thread automatically.
There are many java daemon threads running automatically e.g. gc, finalizer etc.
If you want to make a user thread as Daemon, it must be done before it is started. Otherwise it will throw IllegalThreadStateException.


Virtual Thread (java 19)
========================

Before Virtual Thread was introduced:
-------------------------------------
For every incoming request, a thread is needed to process the request.
One Java thread corresponds to one operating system thread, and those are resource-hungry.

You should not start more than a few thousand; otherwise, you risk the stability of the entire system.
However, a few thousand are not always enough – especially for long running tasks as it needs to wait for blocking data structures, such as queues, locks, or external services like databases, microservices, or cloud APIs.

So far, we have only been able to overcome this problem with asynchronous programming such as CompletableFuture or reactive frameworks like RxJava and Project Reactor.

However, their code is complex than sequential code, hard to read and maintain, and also extremely difficult to debug.
It would make no sense to set a breakpoint here because the code only defines the asynchronous flow but does not execute it. The business code will be executed in a separate thread pool at a later time.


What is Virtual Thread:
-----------------------
- Introduced in Java 19 as preview feature and became production-ready in Java 21.
- The existing/usual threads will now on be referred as Platform Threads which are mapped to and executed by OS Threads.
- The Virtual Thread is mounted on top of and executed by Platform Thread.
- Virtual Threads are lightweight and use lesser resources like CPU, RAM etc.
- So we can create and execute a lot more Virtual Thread compared to Platform Thread.
- The Virtual Thread can reside in one of the 3 queues: 
  - MOUNTED Virtual Thread
  - UNMOUNTED READY Virtual Thread
  - UNMOUNTED BLOCKED Virtual Thread
- When the Virtual Thread is created, they are not mounted automatically.
- They are internally queued up in 'Unmounted Ready Virtual Thread' (as a Stack of Virtual Threads in heap memory) for Platform Thread to pick up later.
- The Virtual machine will have few or multiple Platform Threads to execute incoming Virtual Threads.
- When a Virtual thread is performing some blocking operation (such as I/O or network task), it is then placed in the 'Unmounted Blocked Virtual Thread'. Then another Virtual Thread from Ready queue is picked up for execution.
- Once the Virtual Thread that was put in Blocking queue has completed its operation it is placed in the Ready queue for subsequent execution.


Pinned Virtual Threads:
-----------------------
The JVM mounts virtual thread to platform thread (carrier thread), and executes until it reaches a blocking operation.
Then, the virtual thread is unmounted from the carrier thread, and the scheduler decides which virtual thread to schedule on the carrier thread.

However, there are some cases where a blocking operation doesn’t unmount the virtual thread from the carrier thread, blocking the underlying carrier thread. 
In such cases, we say that the virtual thread is pinned to the carrier thread.
It’s not an error but a behavior that limits the application’s scalability.

Note that if a carrier thread is pinned, the JVM can always add a new platform thread to the carrier pool if the configurations of the carrier pool allow it.

Fortunately, there are only two cases in which a virtual thread is pinned to the carrier thread:
  - When it executes code inside a synchronized block or method.
  - When it calls a native/foreign function (i.e., a call to a native library using JNI).


Core Java Examples:
-------------------
  - To create and start a Platform Thread.
      Thread myThread = Thread.ofPlatform().start(runnable);

  - To create and start a Virtual Thread immediately.
      Thread myThread = Thread.ofVirtual().start(runnable);

  - To create a Virtual Thread but not start immediately.
      Thread myThread = Thread.ofVirtual().unStarted(runnable);
	  myThread.start();
	  
  - This executor method does not use a thread pool but creates a new virtual thread for each task.
    Executors.newVirtualThreadPerTaskExecutor();


Virtual Threads With Jakarta EE:
--------------------------------
To run this controller on a virtual thread, we just add an annotation @RunOnVirtualThread:

  @GET
  @Path("/product/{productId}")
  @RunOnVirtualThread
  public ProductPageResponse getProduct(@PathParam("productId") String productId) { ... }


Virtual Threads With Spring:
----------------------------
According to the Spring documentation, you have to define the following two beans.
This results in all controllers running on virtual threads, which may be fine for most use cases, but not for CPU-heavy tasks – those should always run on platform threads.

  @Bean(TaskExecutionAutoConfiguration.APPLICATION_TASK_EXECUTOR_BEAN_NAME)
  public AsyncTaskExecutor asyncTaskExecutor() {
    return new TaskExecutorAdapter(Executors.newVirtualThreadPerTaskExecutor());
  }
  
  @Bean
  public TomcatProtocolHandlerCustomizer<?> protocolHandlerVirtualThreadExecutorCustomizer() {
    return protocolHandler -> {
      protocolHandler.setExecutor(Executors.newVirtualThreadPerTaskExecutor());
    };
  }


Advantages of Virtual Threads:
------------------------------
They can be created much faster than platform threads.
They require less memory.
Blocking virtual threads is cheap because a blocked virtual thread does not block an OS thread.
Minimal changes have been made to the Thread and ExecutorService APIs.
Instead of writing asynchronous code with callbacks, we can write code in traditional blocking thread-per-request style.
We can debug, observe, and profile virtual threads with existing tools.



Structured Concurrency:
=======================
What is Structured Concurrency:
-------------------------------
Structured Concurrency treats groups of related tasks running in different threads as a single unit of work (as scope), thereby streamlining error handling and cancellation, improving reliability and enhancing observability.

The principal class of the structured concurrency API is StructuredTaskScope in the java.util.concurrent package.

With a StructuredTaskScope instance, you fork each subtask, which runs them in their own individual thread.
After, you join them as a unit. As a result, the StructuredTaskScope ensures that the subtasks are completed before the main task continues.

Implementation plan:
--------------------
To use the StructuredTaskScope class, you follow these general steps:
  1. Create a StructuredTaskScope; use it with a try-with-resources statement.
  2. Define your subtasks as instances of Callable.
  3. Within the try block, fork each subtask in its own thread with StructuredTaskScope::fork.
  4. Call StructuredTaskScope::join.
  5. Handle the outcome from the subtasks.
  6. Ensure that the StructuredTaskScope is shut down.

The StructuredTaskScope class contains two subclasses, ShutdownOnFailure and ShutdownOnSuccess. 
- ShutdownOnFailure cancels all remaining subtasks if one of them fails.
- ShutdownOnSuccess cancels all remaining subtasks if one of them succeeds.
These shutdown policies are examples of short-circuiting patterns.

Benefits of using Structured Concurrency:
-----------------------------------------
Thread lifecycle management - All the threads are managed by the concept of scope.
Error/Exception handling.
Resource cleanup is done automatically when scope is completed.


Implementation steps:
---------------------
1. Enable preview feature option in pom.xml file.
    <compilerArgs>--enable-preview</compilerArgs>

2. Create a class that performs basic flow of StructuredTaskScope.

  public class GitHubUserRepositories {
  
    public GitHubUser findGitHubUser(UserId userId) throws ExecutionException, InterruptedException {
      try (var scope = new StructuredTaskScope<>()) {
  
        var user = scope.fork(() -> findUserByIdPort.findUser(userId));
        var repositories = scope.fork(() -> findRepositoriesByUserIdPort.findRepositories(userId));
  	  
  	    scope.join();  // join all threads within the scope
  	    scope.throwIfFailed();  // throw exception if anything fails
        
  	    LOGGER.info("Both forked task completed");
        System.out.println(user.get() + "\n" + repositories.get());
      }
    }
  }


ShutdownOnFailure Example:
--------------------------
This cancels all subtasks if one of them fails.

Consider a case where 2 dependent tasks are executed within the scope. If the first task fails, there is no need to run the second one. The will save a lot of system resources as well, depending on the task complexity.

public class GitHubUserRepositories {
    public GitHubUser findGitHubUser(UserId userId) throws ExecutionException, InterruptedException {
      try (var scope = new StructuredTaskScope.ShutdownOnFailure()) {
        ....
      }
    }
  }

ShutdownOnSuccess Example:
--------------------------
This cancels all remaining subtasks if one of them succeeds.

Consider a case when task1 gets user information from cache and task2 get user information from database.
Ideally, if the data is available in cache, there is no need to look for it in database. And since the cache is usually faster, task1 will complete first (if data found), and task2 should not run.

public class GitHubUserRepositories {
    public GitHubUser findGitHubUser(UserId userId) throws ExecutionException, InterruptedException {
      try (var scope = new StructuredTaskScope.ShutdownOnSuccess()) {
        ....
      }
    }
  }


Scoped Values:
==============
Scoped Values was first introduced as incubator feature in Java 20 and preview feature in Java 21.
This can be a replacement for ThreadLocal in certain situations.
However, there could still be scenarios where ThreadLocal are useful and can't be replaced by Scoped Values.

Let us look at an example of ThreadLocal:
public class Main {
  private static final ThreadLocal<String> threadLocal = new ThreadLocal<>();

  public static void main(String[] args) {
    final int numOfThreads = 5;
	try(var service = Executors.newFixedThreadPool(numOfThreads)) {
	  for(int i=0; i<numOfThreads; i++) {
	    service.submit(() -> {
		  threadLocal.set(Thread.currentThread().getName());
		  System.out.println(threadLocal.get());
		});
	  }
	}
  }
}

output:
pool-1-thread-2
pool-1-thread-5
pool-1-thread-1
pool-1-thread-3
pool-1-thread-4

Note that, the order in which the thread name prints might change. But if the implementation is correct, the program is never going to print same thread name more than once.


Problems with using ThreadLocal:
--------------------------------
1. Unconstrained Mutability:
When a value is set using ThreadLocal and later on trying to get the value, there is nothing preventing us from setting a different value by the same thread.
This ability might look nice from the context of flexibility to set values as many time as we need.
But it becomes difficult to understand the expected value with the pretty large code base with huge call stack under.

2. Unbounded Lifetime:
Consider there are many thread and they are sharing same ThreadLocal.
When thread-1's task is completed, we would ideally call remove method to GC the value stored.
If this is not done, it results in memory leak, inefficient memory management especially with complex object being stored in ThreadLocal.
The issue is going to exist until all the threads complete their tasks.
It could be even worse, if the thread (whose ThreadLocal value is not removed) goes back to thread pool and a new request tries to access the value, then it returns the old/unexpected value.

3. Expensive Inheritance:
ThreadLocal variables of a parent thread can be inherited by child threads. A ThreadLocal variable is not, in fact, local to one thread.
When we to create a child thread that inherits ThreadLocal variables, the child thread has to allocate storage for every ThreadLocal variable previously written in the parent thread. This can add significant memory footprint.



A example of implementation of Scoped Values is shown below.
ScopedValue does not have getters and setters to overcome Unconstrained Mutability.
They define the scope using where() method. So as long as the get() method is within the scope of where() method, we can get the value successfully.


public class Main {
  private static final ScopedValue<String> scopedValue = ScopedValue.newInstance();

  public static void main(String[] args) {
    final int numOfThreads = 5;
	try(var service = Executors.newFixedThreadPool(numOfThreads)) {
	  for(int i=0; i<numOfThreads; i++) {
	    service.submit(() -> {
		  ScopedValue
		    .where(scopedValue, Thread.currentThread().getName())
			.run(()->{
		      System.out.println(scopedValue.get());
			});
		});
	  }
	}
  }
}


We can even call another method from within the where method and use the scopedValue, even without passing it as argument.

  service.submit(() -> {
    ScopedValue
      .where(scopedValue, Thread.currentThread().getName())
  	  .run(()->{
        doSomething()
  	  });
  });
  
  public void doSomething() {
    System.out.println(scopedValue.get());
  }


Benifits of Scoped Values:
--------------------------
1. In case of Scoped Values (when compared to ThreadLocal), we get better understanding about where we set and get values.
We can do rebinding a new value within the scope as shown below.


  service.submit(() -> {
    ScopedValue
      .where(scopedValue, Thread.currentThread().getName())
  	  .run(()->{
        doSomething()
  	  });
  });
  
  public void doSomething() {
    System.out.println(scopedValue.get());
	ScopedValue
      .where(scopedValue, "A new value")
  	  .run(()->{
        System.out.println(scopedValue.get());
  	  });
  }


2. We can also chain multiple where() methods to set values for different Scoped Values.

ScopedValue
  .where(scopedValue, "A new value")
  .where(scopedValue2, "Another value")
  ...
  .run(()->{
	System.out.println(scopedValue.get());
  });


If the code uses ThreadLocal and sets values multiple times, then migrating to Scoped Values is difficult and does not make sense.

If the Scoped Value variable is accessed outside the scope, the NoSuchElementException is thrown.
scopedValue.isBound() method is used to check if the value is within the scope and whether is can be accessed.






Java Memory Model:
==================
  - In the Java memory area, each Thread will have its own Thread Stack. It is not shared with other threads.
  - Also, Heap memory area is shared across threads.
  - In the Thread stack all local variables are stored.
  - The reference to objects defined inside methods are also stored in the stack.
  - However, the actual object itself is stored in Heap memory area.


The below diagram shows basic structure how threads, stack, heap are arranged.

	+------------------------------------------+
	|                                          |
	|	+--------------+    +-------------+    |
	|	|  Thread 1	   |    |  Thread 2   |    |
	|	+--------------+    +-------------+    |
	|                                          |
	|	+--------------+    +--------------+   |
	|   |			   |    |		       |   |
	|   | Thread Stack |    | Thread Stack |   |
	|	|			   |    |			   |   |
	|	+--------------+    +--------------+   |
	|                                          |
	|	+----------------------------------+   |
	|	|                                  |   |
	|	|        Common Heap Area          |   |
	|	|                                  |   |
	|	+----------------------------------+   |
	|										   |
	+------------------------------------------+



Let us understand the above concept using an example.

  public class MyRunnable implements Runnable {
    private int count = 0;
	
	public void run() {
	  Object myObj = new Object();
	  for(int i=0; i<1000; i++) {
	    this.count++;
	  }
	  
	  System.out.println(Thread.currentThread().getName() + ":" + this.count);
	}
  }
  
  public class SeperateOjects {
    public static void main(String[] args) {
	
	  int myLocalVar = 0;  // stack
	  String myLocalString = "val";  // reference variable in stack. Actual object, i.e., "val" in heap
	  
	  Runnable r1 = new MyRunnable();
	  Runnable r2 = new MyRunnable();
	  
	  Thread t1 = new Thread(r1, 'Thread 1');
	  Thread t2 = new Thread(r2, 'Thread 2');
	  
	  t1.start();
	  t2.start();
	}
  }


  public class SharedObjects {
    public static void main(String[] args) {
	  Runnable runnable = new MyRunnable();
	  
	  Thread t1 = new Thread(runnable, 'Thread 1');
	  Thread t2 = new Thread(runnable, 'Thread 2');
	  
	  t1.start();
	  t2.start();
	}
  }



How Java Memory model look like from hardware perspective:
----------------------------------------------------------

	+----------------------------------------------------------+
	|                                                          |
	|    +--------------------+      +--------------------+    |
	|    | CPU			      |      | CPU				  |    |
	|    | 					  |      |					  |    |
	|    |	   [ Thread ]     |      |	 [ Thread ]    	  |    |
	|	 |					  |      |					  |    |
	|	 | +----------------+ |      | +----------------+ |    |
	|	 | |  CPU Register  | |      | |  CPU Register  | |    |
	|	 | +----------------+ |      | +----------------+ |    |
	|	 +--------------------+      +--------------------+    |
	|                                                          |
	|	 +--------------------+      +--------------------+    |
	|    |					  |      |					  |    |
	|    |  L1, L2, L3 Cache  |      |  L1, L2, L3 Cache  |    |
	|	 |					  |      |					  |    |
	|	 +--------------------+      +--------------------+    |
	|                                                          |
	|	 +------------------------------------------------+	   |
	|    | RAM					         				  |    |
	|    |	+----------------+		+----------------+	  |    |
	|    |	|  CPU Register  |		|  CPU Register  |	  |    |
	|	 |  +----------------+      +----------------+    |    |
	|	 |          +--------------------+                |    |
	|	 |          |  Common Heap Area  |                |    |
	|	 |          +--------------------+                |    |
	|	 +------------------------------------------------+    |
	|													 	   |
	+----------------------------------------------------------+


  - Consider there are multiple cores inside the CPU.
  - Lets suppose there are 2 different threads and run on each CPU core.
  - Each CPU core will have their own CPU register.
  - In between CPU register and RAM memory area, there would be Cache (L1, L2, L3) regions.
  - RAM contains Thread stack and Heap area.
  - So the data storage flow would look like below,
    - For local variables, CPU Register -> Cache -> RAM's Thread Stack.
	- For instance variables and objects, CPU Register -> Cache -> RAM's Heap area.

  - However with this memory model in place, we can have one or many of the following problems.

    - Race condition:
	  - If multiple threads access data in heap and they read and write data in non-synchronized manner.
	  - Consider an object myObj resides in heap. This object also contains instance variable count.
	  - Now if 2 threads trying to increment count value, each gets their own copy to increment without knowing that other thread is also accessing at the same time. Then, instead of incrementing twice, it is incremented once.
	  - This can be solved using 'synchronized' or 'volatile'.

	- Data write visibility:
	  - Consider one thread updates the value. if the other thread accesses its value before it is written back to memory, it results in inconsistency (the update is missed).
	  - This can also be solved using 'synchronized' or 'volatile'.

  - This issue is illustrated in the below example. Here, the Runnable object is shared by 2 threads. So the final output is always less than 2000000.
  

public class MyRunnable implements Runnable {
    private int count = 0;
	
	public void run() {
	  for(int i=0; i<1000000; i++) {
	    this.count++;
	  }
	  
	  System.out.println(Thread.currentThread().getName() + ":" + this.count);
	}
  }

  public class SharedObjects {
    public static void main(String[] args) {
	  Runnable runnable = new MyRunnable();
	  
	  Thread t1 = new Thread(runnable, 'Thread 1');
	  Thread t2 = new Thread(runnable, 'Thread 2');
	  
	  t1.start();
	  t2.start();
	}
  }

Sample output:
Thread 2: 1091521
Thread 1: 1917670


CPU Cache Coherence:
====================
- All variables visible to the thread which are stored in CPU registers will be flushed to main RAM (main memory).
- On the way to main RAM the variables may be stored in the CPU cache. 
- The CPU then uses its cache coherence methods to make sure that all other CPUs caches can see the variables in the first CPUs cache.
- However, it is not guaranteed that the data is visible from other cache.

- The hardware may even choose not to flush the variables to main memory but keep it in the CPU cache.
- When the Cache is full and have no space for other data, the CPU cache can then be flushed to main memory.



Java happens before guarantee:
==============================
- Java Happens Before Guarantee is the set of instruction reordering to avoid instruction reordering from breaking the Java visibility guarantees.


Instruction Reordering:
-----------------------
- Let us understand the instruction reordering.
- If a method or piece of code contains multiple instructions, CPU can excute them in parallel, if they are not dependent on each other. 
- For example:
    a = b + c;  // i1
	d = a + e;  // i2
	
	f = g + h;  // i3
	i = j + k;  // i4
	
- In the above example, i2 is dependent on i1. i4 is dependent on i3. So i1 and i2 cannot run in parallel. Same is true in case of i3 and i4.
- However, i1 and i3 can run in parellel. Same is true in case of i2 and i4. This reordering will be performed by JVM.



Two threads communicating via shared object:
--------------------------------------------

Visibility Guarantee:
---------------------
If multiple threads are executed in parallel with shared object, it could result in unexpected behavior.
Let us understand with an example.

Example code:
-------------
public class FrameExchanger  {

  private long framesStoredCount = 0:
  private long framesTakenCount  = 0;
  private boolean hasNewFrame = false;
  private Frame frame = null;

  public void storeFrame(Frame frame) {  // called by Frame producing thread
    this.frame = frame;
    this.framesStoredCount++;
    this.hasNewFrame = true;
  }

  public Frame takeFrame() {  // called by Frame drawing thread
    while( !hasNewFrame) {
      //busy wait until new frame arrives
    }
    Frame newFrame = this.frame;
    this.framesTakenCount++;
    this.hasNewFrame = false;
    return newFrame;
  }
}


Consider an application that has 2 threads running on seperate CPUs.
Thread1 PRODUCES frames to be drawn on the screen.
Thread2 CONSUMES these frames and DRAWS on the screen.

These 2 threads communicate via shared instance of FrameExchanger class. This instance is stored in shared memory.
However, when the thread executes it takes a copy of the instance (and their variables) and stores in its own CPU register.

Since neither the variables are declared volatile nor the methods storeFrame() and takeFrame() are marked synchronized, there is no guarantee that changes made to the values by one thread is visible/reflected to the other thread.
This is called Visibility Problem.
To avoid this, the thread1 has to write the updates into the shared main memory. Also, thread2 has to read the updated values from the main memory.
This can be done by declaring the instance variables with volatile keyword as shown below.

  private volatile long framesStoredCount = 0:
  private volatile long framesTakenCount  = 0;
  private volatile boolean hasNewFrame = false;
  private volatile Frame frame = null;

When a field is declared volatile
  - all the updates made to the fields are directly flushed to the main memory.
  - all the reads made on the fields are directly read from the main memory.

It should be noted that, not all the fileds are required to be declared as volatile. Only the last field whose value is changed needs to be declared volatile.
In the FrameExchanger class, the thread1 which executes storeFrame() method, the hasNewFrame variable is updated as last statement. So only that instance variable is required to be declared volatile. All the update statement that precedes the last statement are visible and are automatically flushed to main memory.
Similarly, the thread2 which executes takeFrame() method, the hasNewFrame variable is updated as last statement.


Instruction reordering may break the volatile visibility guarantee:
-------------------------------------------------------------------
Let us examine the method below.
  public void storeFrame(Frame frame) {
    this.frame = frame;
    this.framesStoredCount++;
    this.hasNewFrame = true;  // marked volatile
  }

From the CPU perspective the instruction inside this method are independent and may reorder the instruction.
If "this.hasNewFrame = true;" is reordered as first statement, then when that statment is executed all the previous statements would get flushed to the main memory. However, the subsequent statements are not flushed to main memory.


Volatile Happens Before Guarantee:
----------------------------------
As seen in the above scenario, instruction reordering may break the volatile visibility guarantee.
To overcome this Java provides Volatile Happens Before Guarantee.

Any write to variables that happen before the a write to volatile variable, will remain before the write to volatile variable.
However if there are multiple write statements before the write to volatile variable, they can be reordered among themselves but not after/with the volatile variable.

Similarly any read of a volatile variable that is located before reads of other non-volatile or volatile variables are guaranteed to happen before any of these subsequent reads.


Synchronized Visibility Guarantee:
----------------------------------
Consider the below code:

public class ValueChanger {
  private int valA;
  private int valB;
  private int valC;
  
  public void setVal(MyValClass v) {
    synchronized(this) {
	  this.valA = v.valA;
	  this.valB = v.valB;
	  this.valC = v.valC;
	}
  }
  
  public void getVal(MyValClass v) {
    synchronized(this) {
	  v.valA = this.valA;
	  v.valB = this.valB;
	  v.valC = this.valC;
	}
  }
}

Java has challenges with instruction reordering in context of synchronized blocks.
In the above example,
- Thread 1 will call setVal() method with MyValClass object as parameter and sets the value to ValueChanger instance variables.
- Thread 2 will call getVal() method with MyValClass object as parameter and sets the values of ValueChanger instance variables to corresponding values of MyValClass object.

The Java Synchronized Visibility Guarantee states following points.
- When a thread enters a synchronized block, all the variables that are visible to the thread at that time (i.e., all variables inside synchronized block) will be refreshed from the main memory.
- When the thread exits the synchronized block, all the variables that are visible to the thread at that time wil be flushed to the main memory.


Instruction Reordering may break the Synchronized Visibility Guarantee:
-----------------------------------------------------------------------
Now consider the instructions in these methods were reordered as follows.

public class ValueChanger {
  private int valA;
  private int valB;
  private int valC;
  
  public void setVal(MyValClass v) {
    synchronized(this) {
	  this.valA = v.valA;
	  this.valB = v.valB;
	}
	this.valC = v.valC;
  }
  
  public void getVal(MyValClass v) {
    v.valA = this.valA;
    synchronized(this) {
	  v.valB = this.valB;
	  v.valC = this.valC;
	}
  }
}

In method setVal() the assignment to valC is reordered outside and after the synchronized block.
In method getVal() the read of valA is reordered outside and before the synchronized block.
As we know, this reordering would changes the visibility guarantees.

By the time Thread1 exits synchronized block of setVal() method, only valA and valB are flushed to the main memory. So value of valC becomes outdated.
Similarly, when Thread2 enters synchronized block of getVal() method, valA may not have been refreshed from the main memory.


Synchronized Happens Before Guarantee:
--------------------------------------
In order to fix the above mentioned problem, java synchronized block comes with Happens Before Guarantee.
It states that,
- Any write to a variable before the exit of synchronized block is guaranteed to remain before exit of the block. In fact, any writes to variables that happens before the synchronized block itself, they cannot be reordered after the block.
- The entry to synchronized block that happens before the reads of variable is guaranteed to remain before any of these reads to variables that follow the entry of the synchronized block. In other words, none of the reads inside and/or after the synchronized block could be reordered before the entry of synchronized block.



Synchronization in Java:
========================
A synchronized block is a block that can be executed by only one thread at a time.
Declaring instance method synchronized means that only one thread can access that method at a time.
If there are multiple synchronized methods, then only one thread can access only one of these methods at a time.

Synchronized keyword can be used in
- Instance Methods
- Static Methods

Synchronized keyword can also be used for a block of code (instead of whole method) inside,
- Instance Methods
- Static Methods
- Lambda Expressions

- The object on which the synchronization is applied is called Monitor object. 
- Eg: synchronized(this) means the current class' object is the monitor object.
- the monitor object can not be null.


Example: Synchronized on instance method:
-----------------------------------------
public class SynchronizedExchanger {
  protected Object object = null;
	
  public synchronized void setObject(Object obj) {
    this.object = obj;
  }
	
  public synchronized Object getObject() {
    return this.object;
  }
	
  public void setObj(Object obj) {
    synchronized(this) {
      this.object = obj;
    }
  }
	
  public Object getObj() {
    synchronized(this) {
      return this.object;
    }
  }
}


- Let us consider that Thread 1 will execute setObject(..) and setObj(..). Similarly getObject() and getObj() will be executed by Thread 2.
- Now, if Thread 1 and Thread 2 works on the single shared SynchronizedExchanger object, and if Thread 1 enters one of the 4 methods, then Thread 2 has to wait for Thread 1 to complete its execution to enter one the remaining 3 methods. 
- However, if Thread 1 and Thread 2 works on different SynchronizedExchanger object, if Thread 1 enters setObject(..) (or setObj(..)) method, Thread 2 can start executing getObject() (or getObj()) method. It does not have to wait for Thread 1 to complete its execution.


- The monitor object in the synchronized method will always hold the current class' object.
- However, the monitor object in the synchronized block can hold object of any class.

- The static method marked as synchronized will always hold the class' object and not instance object as monitor.


Example: Synchronized on static method:
---------------------------------------
public class SynchronizedExchanger {
  protected static Object object = null;
	
  public static synchronized void setObject(Object obj) {
    object = obj;
  }
	
  public static synchronized Object getObject() {
	return object;
  }
	
  public static void setObj(Object obj) {
	synchronized(SynchronizedExchanger.class) {
	  object = obj;
	}
  }
	
  public static Object getObj() {
    synchronized(SynchronizedExchanger.class) {
      return object;
    }
  }
}

- Now, as all the methods and the instance object are static, if Thread 1 enters one of the 4 methods, then Thread 2 has to wait for Thread 1 to complete its execution to enter one the remaining 3 methods. 


Example: Synchronized on static and instance method (mixed):
------------------------------------------------------------
public class MixedSynchronization {
  protected static Object staticObject = null;
  public static synchronized void setStaticObject(Object obj) {
    staticObject = obj;
  }
	
  protected  Object instanceObject = null;
  public synchronized void setInstanceObject(Object obj) {
	this.instanceObject = obj;
  }
}

- A class can have both static and instance method synchronized. 
- In that case, setStaticObject(..) is synchronized on the MixedSynchronization class object and setInstanceObject(..) is synchronized on specific instance of the MixedSynchronization class.
- So one Thread can access the setStaticObject(..) at the same time another thread accessing setInstanceObject(..) method.
- If 2 Thread access setStaticObject(..) they will be blocked.
- If 2 Thread access setInstanceObject(..) they will not be blocked, unless the objects are not same.


Using different monitor objects in same class:
----------------------------------------------
public class MultipleMonitorObjects {

  private Object monitorOne = new Object();
  private Object monitorTwo = new Object();

  public void method1() {
    synchronized(this.monitorOne) { .. }
  }

  public void method2() {
    synchronized(this.monitorTwo) { .. }
  }
}


Sharing monitor objects:
------------------------
public class SharedMonitorObject {
  private Object monitor = null;
  private int counter = 0;

  public SharedMonitorObject(Object mObj) {
    if(mObj == null) { throw new IllegalArgumentException("Monitor object cannot be null"); }
	this.monitor = mObj;
  }
  
  public void incCounter() {
    synchronized(this.monitor) { this.counter++; }
  }
}


public class SharedMonitorObjectMain {
  public static void main() {
    
	Object monitor1 = new Object();
	SharedMonitorObject smo1 = new SharedMonitorObject(monitor1);
	SharedMonitorObject smo2 = new SharedMonitorObject(monitor1);
	smo1.incCounter();
	smo2.incCounter();
	
	Object monitor2 = new Object();
	SharedMonitorObject smo3 = new SharedMonitorObject(monitor2);
	smo3.incCounter();
  }
}

- In the above example, smo1 and smo2 work on the same monitor object. So only one thread can access the incCounter() method. 
- But it is independent of smo3 as it works on different monitor object.

- Never use, String objects like "monitor1" as monitor object as we will not know if two different string monitor objects with same value will refer to same value in heap.


Synchronized block inside Lambda Expression:
--------------------------------------------

public class SynchronizedLambda {
  private static Object object = null;
	
  public static synchronized void setObject(Object obj) {
    object = obj;
  }
	
  public static void consumeObject(Comsumer comsumer) {
    consumer.accept(object);
  }
	
  public static void main(String[] args) {
    consumeObject( (obj) -> {
	  synchronized(SynchronizedLambda.class) {
	    System.out.println(obj);
	  }
	});
	
	consumeObject( (obj) -> {
	  synchronized(String.class) {
	    System.out.println(obj);
	  }
	});
  }
}


Java synchronized Reentrance rules:
-----------------------------------
public class Reentrance {
  private int count = 0;
  
  public synchronized void inc() {
    this.count++;
  }
  
  public synchronized int incAndGet() {
    inc();
	return this.count;
  }
}


- Once a thread has entered a synchronized block the thread is said to "hold the lock" on the monitor object the synchronized block is synchronized on.
- If the thread calls another method which calls back the first method with the synchronized block inside, the thread holding the lock can reenter the synchronized block.
- It is not blocked just because a thread (itself) is holding the lock. Only if a different thread is holding the lock, it can not enter the subsequent method.


Limitation and drawbacks of Synchronized blocks:
------------------------------------------------
1. Only one thread can enter the synchronized method/block at a time.
2. There is no guarantee about the sequence in which waiting threads gets access to the synchronized block.
3. Performance overhead of entering and exiting synchronized blocks.



Java Volatile keyword:
======================
The Java volatile keyword when applied to a variable, we tell JVM that that variable must always written and read directly from the main memory.

- Non-volatile variable Visibility Problems
- The Java volatile Visibility Guarantee
- Instruction Reordering could break volatile visibility guarantee
- The Java volatile Happens-Before Guarantee
- Performance Considerations of volatile
- volatile is Not Always Enough


CPU Cache Coherence and Concurrency:
====================================
False statement:
Writes to volatile variables or exiting a synchronized block flushes thread visible variable from CPU Cache to main memory.

True statement:
Writes to volatile variables or exiting a synchronized block flushes thread visible variable from CPU Register to main memory.
When writing the data from CPU register, the hardware will first store it in Cache and then write it to main memory.

The hardware may even choose not to flush the data all the way down to main memory. The other threads running in other CPUs/Cores are able to see the data stored in other CPU's caches.
This is called Cache Coherence.

Sooner or later the hardware will likely flush the data from the cache to the main memory.




Java ThreadLocal:
==================
ThreadLocal class enables you to create variables that can only be read and written by the same thread.
Thus, even if two threads are executing the same code, and the code has a reference to the same ThreadLocal variable, the two threads cannot see each other's values stored in ThreadLocal variable.


Creating a ThreadLocal:
-----------------------
private ThreadLocal myThreadLocal = new ThreadLocal();

This only needs to be done once per thread. Multiple threads can now get and set values inside this ThreadLocal, and each thread will only see the value it set itself.


Set ThreadLocal Value:
----------------------
Once a ThreadLocal has been created you can set the value to be stored in it using its set() method.
myThreadLocal.set("A thread local value");


Get ThreadLocal Value:
----------------------
You read the value stored in a ThreadLocal using its get() method.
String myThreadLocalValue = (String) myThreadLocal.get();


Remove ThreadLocal Value:
-------------------------
You remove a value by calling the ThreadLocal remove() method. 
myThreadLocal.remove();


Generic ThreadLocal:
--------------------
Using a generic type only objects of the generic type can be set as value on the ThreadLocal. 
Additionally, you do not have to typecast the value returned by get().

private ThreadLocal<String> myThreadLocal = new ThreadLocal<String>();
myThreadLocal.set("Hello ThreadLocal");
String myThreadLocalValue = myThreadLocal.get();


Initial ThreadLocal Value:
--------------------------
Two options for specifying an initial value for a ThreadLocal:

1. Create a ThreadLocal subclass that overrides the initialValue() method.
private ThreadLocal myThreadLocal = new ThreadLocal<String>() {
  @Override protected String initialValue() {
    return String.valueOf(System.currentTimeMillis());
  }
};

2. Create a ThreadLocal with a lambda expression (Supplier interface).
ThreadLocal threadLocal = ThreadLocal.withInitial(
    () -> { return String.valueOf(System.currentTimeMillis()); } );


Lazy Setting of ThreadLocal Value:
----------------------------------
It is also possible to set the ThreadLocal lazily.

main(String[] args) {
  ThreadLocal<String> threadLocal = new ThreadLocal<>();
  
  String value = threadLocal.get();
  if(value == null) {
    threadLocal.set("Lazily set value");
	value = threadLocal.get();
  }
  System.out.println(value);
}


Using ThreadLocal and ThreadPool:
---------------------------------
Consider we have 4 tasks T1, T2, T3, T4. Thread1 executes tasks T1 & T4. Thread2 executes tasks T2 & T3. So the value set using tasks T1 & T4 will be same (shared among them). The point is true for the other 2 tasks too. Note that, here the value is unique for each threads and not each tasks.


Inheritable ThreadLocal:
------------------------
The InheritableThreadLocal class is a subclass of ThreadLocal. Instead of each thread having its own value inside a ThreadLocal, the InheritableThreadLocal grants access to values to a thread and all child threads created by that thread.

Example:
--------
public class InheritableThreadLocalExample {

  public static void main(String[] args) {
    ThreadLocal<String> parentTL = new ThreadLocal<>();
	InheritableThreadLocal<String> inheritableTL = new InheritableThreadLocal<>();
	
	Thread parentThread = new Thread(() -> {
	  System.out.println("== Parent Thread ==");
	  parentTL.set("Parent Thread - ThreadLocal");
	  inheritableTL.set("Parent Thread - Inheritable ThreadLocal");
	  
	  System.out.println(parentTL.get());
	  System.out.println(inheritableTL.get());
	  
	  Thread childThread = new Thread(() -> {  // a thread defined within another thread
	    System.out.println("== Child Thread ==");
	    System.out.println(parentTL.get());
	    System.out.println(inheritableTL.get());
	  });
	  childThread.start();
	});
	parentThread.start();
	
	Thread thread2 = new Thread(() -> {  // another independent thread
	  try {  Thread.sleep(3000);  }
	  catch(InterruptedException ex) {  e.printStackTrace();  }
	  
	  System.out.println("== Thread 2 ==");
	  System.out.println(parentTL.get());
	  System.out.println(inheritableTL.get());
	});
  }
}

Output:
== Parent Thread ==
Parent Thread - ThreadLocal
Parent Thread - Inheritable ThreadLocal
== Child Thread ==
null
Parent Thread - Inheritable ThreadLocal
== Thread 2 ==
null
null



Race condition:
===============
- Race condition is a situation where two or more threads access the same variable/data in a way where the final result depends on how thread access to the variables is scheduled.
- Race condition occur when two or more threads read and write the same variable/data concurrently.

- If one thread writes and another threads just reads data, then possiblility of occurance of race condition is quite rare. However, it is always better to synchronize the code to avoid visibility problem.

- If two threads access two different objects but write/update them seperately, there wont be a race problem. 
- Eg: Thread 1 updates counter1 and just reads counter2. Thread 2 updates counter 2 and just reads counter1.
    Thread thread1 = new Thread(getRunnable(counter1, counter2, "Thread 1"));
	Thread thread2 = new Thread(getRunnable(counter2, counter1, "Thread 2"));


- The threads access the variables using either of these patterns:

Read-Modify-Write:
------------------
Two threads trying to increment same object/variable:
-----------------------------------------------------
- The condition where the modified value depends on the previously read value.


Example:
public class RaceConditionsExample {
  public static void main(String [] args) {
    Counter counter = new Counter();
    
    Thread thread1 = new Thread(getRunnable(counter, "Thread1 final count: "));
    Thread thread2 = new Thread(getRunnable(counter, "Thread2 final count: "));
    
    thread1.start();
    thread2.start();
  }

  private static Runnable getRunnable(Counter counter, String message) {
    return () -> {
      for(int i=0; i<1_000_000; i++) {
  	  counter.incAndGet();
  	}
  	System.out.println("message " + counter.get());
    };
  }
}

public class Counter {
  private long count = 0;

public long incAndGet() {
  this.count++;
  retutn this.count;
}

public long get() {  return this.count;  }
}

- Here the thread access to the variable is not atomic.
- So after one of the threads accesses the value and at the time it is incrementing the value, the other thread accesses the value which is not updated.
- The part of code in which the issue might happen is called critical section (this.count++ in this case).
- This statement is not actually single statement. It consists of reading the value, incrementing it and assigning it back to the variable.
- This can be fixed by making the operation atomic or by enclosing the critical section with synchronized keyword.
  Using Synchronized block:
  - The critical section can be enclosed with synchronized block as follows.
  
  public long incAndGet() {
    synchronized(this) {
      this.count++;
      retutn this.count;
	}
  }


One thread writes and another thread reads:
-------------------------------------------
- As mentioned earlier, if one thread increments value and the other thread just reads it, then the possibility that Race condition might occur is quite less.
- However it is not the guaranteed case as visibility problem might still exist.


Two threads access same object(s) but not write to same object:
---------------------------------------------------------------
- Consider the case when two threads are given runnable instances.
- Each runnable gets two counters are parameters. The runnable increments and prints the first counter and just prints the second counter (but not the same counter).
- So the possibility that Race condition might occur is quite less / not there.

  public class RaceConditionExample2 {
  
    public static void main(String [] args) {
      Counter counter1 = new Counter();
	  Counter counter2 = new Counter();
      
      Thread thread1 = new Thread(getRunnable(counter1, counter2, "Thread 1"));
      Thread thread2 = new Thread(getRunnable(counter2, counter1, "Thread 2"));
      
      thread1.start();
      thread2.start();
    }

    private static Runnable getRunnable(Counter counterA, Counter counterB, String runnableName) {
      return () -> {
        for(int i=0; i<1_000_000; i++) {
    	  counterA.incAndGet();
    	}
    	System.out.println(runnableName + "final count - counterA: " + counterA.get());
		System.out.println(runnableName + "final count - counterB: " + counterB.get());
      };
    }
  }

  public class Counter {
    private long count = 0;
  
    public long incAndGet() {
      this.count++;
      retutn this.count;
    }
    
    public long get() {  return this.count;  }
  }


Check-Then-Act:
---------------
- Check-then-act represents a situation where multiple threads checks for some condition to be true.
- Based on the out-come, they try to change state of the variable.
- By the time thread 'checks' and then 'acts', the condition may have been invalidated by some other threads.

public class CheckThenActExample {
  public void checkThenAct(Map<String, String> sharedMap) {
    if(sharedMap.containsKey("key")){
      String val = sharedMap.remove("key");
      if(val == null) {
        System.out.println("Value for 'key' was null");
      }
    } else {
      sharedMap.put("key", "value");
    }
  }
}

- If two or more threads call the checkThenAct() method on the same CheckThenActExample object, then two or more threads may execute the if-statement at the same time, evaluate sharedMap.containsKey("key") to true, and thus move into the body code block of the if-statement.
- In there, multiple threads may then try to remove the key,value pair stored for the key "key", but only one of them will actually be able to do it.
- The rest will get a null value back, since another thread already removed the key,value pair.


Fun Realtime example:
You are planning to go for a movie at 5 pm. You are inquiring about availability of the tickets at 4 pm. Representative says its available. You relax and reach to the ticket window 5 minutes before the show. And you can guess what. Its house full. The problem here was in the duration between check and act. You inquired at 4 and acted at 5. In the meantime, someone else grabbed the tickets. That’s race condition – specifically check-then-act scenario of race condition.


Preventing Race Conditions:
---------------------------
To prevent race conditions, the critical section must be executed as an atomic instruction, so that, only one thread can execute the critical section at a time.
This can be done in following ways:
- By using a synchronized block.
- By using locks 
- By using atomic variables like AtomicInteger packaged inside java.util.concurrent.atomic.



Concurrency vs Parallelism:
===========================
Concurrency:
------------
  - Concurrency means that an application is making progress on more than one task - at the same time or at least seemingly at the same time (concurrently).
  - In a single CPU computer, the application may not make progress on more than one task at exactly the same time, but more than one task is in progress at a time inside the application. 
  - To make progress on more than one task concurrently the CPU switches (context switching) between the different tasks during execution.

Parallel Execution:
-------------------
  - Parallel execution is when a computer has more than one CPU or CPU core, and makes progress on more than one task simultaneously.

Parallel Concurrent Execution:
------------------------------
  - Parallel concurrent execution is where threads are distributed among multiple CPUs.
  - The threads executed on the same CPU are executed concurrently, whereas threads executed on different CPUs are executed in parallel.

Parallelism:
------------
  - The application splits its tasks up into smaller subtasks which can be processed in parallel, for instance on multiple CPUs at the exact same time.

Concurrency and Parallelism Combinations:
-----------------------------------------
  - Concurrent, Not Parallel
  - Parallel, Not Concurrent
  - Neither Concurrent Nor Parallel
  - Concurrent and Parallel


Thread Pool:
============

Introduction:
-------------
- Creating a new thread everytime for each task comes with a performance overhead. 
- To overcome this, we can reuse existing thread(s) to execute task(s) which results in a higher total throughput.
- So when a task arrives to the queue, one of the thread which is ready for execution will pick it up.
- If there is no task, all the thread will be in idle state.
- If there are tasks which outnumbers number of threads, all the remaining task has to wait for one of the thread (which finishes first) to pick them up.

How Thread Pool works:
----------------------
- Instead of starting a new thread for every task to execute concurrently, the task can be passed to a thread pool.
- Internally the tasks are inserted into a queue called Blocking Queue.
- When a new task is inserted into the queue one of the idle threads will dequeue it successfully and execute it. 

Built-in Java Thread Pool:
--------------------------
- Java comes with built in thread pools in the java.util.concurrent package (java.util.concurrent.ExecutorService), so you don't have to implement your own thread pool.


Thread Pool Implementation:
---------------------------
- As java already provides some Thread Pool implementation, we do not have to implement one by our own.
- However, let us see how the implementation would look like for learning.


PoolThreadRunnable.java:
------------------------
import java.util.concurrent.BlockingQueue;

public class PoolThreadRunnable implements Runnable {
  private Thread        thread    = null;
  private BlockingQueue taskQueue = null;
  private boolean       isStopped = false;

  public PoolThreadRunnable(BlockingQueue queue) {  taskQueue = queue;  }

  public void run() {
    this.thread = Thread.currentThread();
    while(!isStopped()) {
      try {
        Runnable runnable = (Runnable) taskQueue.take();
        runnable.run();
      } catch(Exception e) {  //log or otherwise report exception, but keep pool thread alive.  }
    }
  }

  public synchronized void doStop() {
    isStopped = true;
    this.thread.interrupt();  //break pool thread out of dequeue() call.
  }

  public synchronized boolean isStopped(){  return isStopped;  }
}


ThreadPool.java:
----------------
import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;

public class ThreadPool {
  private BlockingQueue<Runnable> taskQueue = null;
  private List<PoolThreadRunnable> runnables = new ArrayList<>();
  private boolean isStopped = false;

  public ThreadPool(int noOfThreads, int maxNoOfTasks) {
    taskQueue = new ArrayBlockingQueue(maxNoOfTasks);

    for(int i=0; i<noOfThreads; i++) {
      PoolThreadRunnable poolThreadRunnable = new PoolThreadRunnable(taskQueue);
      runnables.add(poolThreadRunnable);
    }
    for(PoolThreadRunnable runnable : runnables) {
      new Thread(runnable).start();
    }
  }

  public synchronized void  execute(Runnable task) throws Exception {
    if(this.isStopped) {  throw new IllegalStateException("ThreadPool is stopped");  }
    this.taskQueue.offer(task);
  }

  public synchronized void stop() {
    this.isStopped = true;
    for(PoolThreadRunnable runnable : runnables) {
      runnable.doStop();
    }
  }

  public synchronized void waitUntilAllTasksFinished() {
    while(this.taskQueue.size() > 0) {
      try {  Thread.sleep(1);  }
	  catch (InterruptedException e) {  e.printStackTrace();  }
    }
  }

}


ThreadPoolMain.java:
--------------------
public class ThreadPoolMain {

  public static void main(String[] args) throws Exception {

    ThreadPool threadPool = new ThreadPool(3, 10);  // 3 threads and 10 tasks

    for(int i=0; i<10; i++) {
      int taskNo = i;
      threadPool.execute( () -> {
        String message = Thread.currentThread().getName() + ": Task " + taskNo ;
        System.out.println(message);
      });
    }

    threadPool.waitUntilAllTasksFinished();
    threadPool.stop();
  }
}


Locks in Java:
==============
Consider a class Counter.
public class Counter {
  private int count=0;
  public void increment {
    count++;
  }
  public int getCount() {
    return count;
  }
}

Here count++ is not an atomic/single operation. 
It does 3 things. get count, increment count, set new value to count.
Also the operation is not thread safe. If more than one thread accesses the method at same time, the output would be undesirable.

Lock method:
------------
To make the above operation thread safe, we add synchronized keyword.
However, only one thread can access synchronized resource(method) and others have to wait. This is lead to performance issue.
In fact, if all/many methods in a class is synchronized, if one thread accesses one of the synchronized methods, lock is applied for all the synchronized methods and other threads can access methods only after the lock is released. Eg: Hashtable.

To address this issue, Lock class is used.
Example:
Above class can be rewritten as follows.

Lock lockObj = new ReentrantLock();
public void increment {
  lockObj.lock();
  count++;
  lockObj.unlock();
}

This way the lock is applied only for the current method. Other threads can access other methods.


- It is a thread synchronization mechanism like synchronized blocks except it can be more sophisticated than synchronized blocks.

Basic example:
--------------
public class Counter {

  private int count = 0;

  public int inc() {
    synchronized(this){ return ++count; }  // using synchronization
  }

  private Lock lock = new Lock();  // using lock
  public int inc() {
    lock.lock();
    int newCount = ++count;  // code that needs synchronization.
    lock.unlock();
    return newCount;
  }
}


The lock() method locks the Lock instance so that all threads calling lock() are blocked until unlock() is executed.

Here is a simple Lock implementation:

public class Lock {
  private boolean isLocked = false;

  public synchronized void lock() throws InterruptedException {
    while(isLocked) {
      wait();
    }
    isLocked = true;
  }

  public synchronized void unlock() {
    isLocked = false;
    notify();
  }
}


Lock Reentrance:
----------------
- Synchronized blocks in Java are reentrant.
- If a thread enters a synchronized block (and acquire lock on the monitor object), the thread can enter other code blocks synchronized on the same monitor object.

eg:
public class Reentrant {
  public synchronized outer() {
    inner();
  }

  public synchronized inner() {
    //do something
  }
}


- The Lock class shown earlier is not reentrant.
- If we rewrite the Reentrant class like below, the thread calling outer() will be blocked inside the lock.lock() in the inner() method.

public class Reentrant2 {

  Lock lock = new Lock();

  public outer() {
    lock.lock();
    inner();
    lock.unlock();
  }

  public synchronized inner() {
    lock.lock();
    //do something
    lock.unlock();
  }
}


- A thread calling outer() will first lock the Lock instance. 
- Then it will call inner(). 
- Inside the inner() method the thread will again try to lock the Lock instance. 
- This will fail (meaning the thread will be blocked), since the Lock instance was locked already in the outer() method.

- To make the Lock class reentrant we need to make a small change:

public class Lock {

  boolean isLocked = false;
  Thread  lockedBy = null;
  int     lockedCount = 0;

  public synchronized void lock()
  throws InterruptedException {
    Thread callingThread = Thread.currentThread();
    while(isLocked && lockedBy != callingThread) {
      wait();
    }
    isLocked = true;
    lockedCount++;
    lockedBy = callingThread;
  }

  public synchronized void unlock() {
    if(Thread.curentThread() == this.lockedBy) {
      lockedCount--;
      if(lockedCount == 0) {
        isLocked = false;
        notify();
      }
    }
  }
  ...
}


Lock Fairness:
--------------
- Synchronized blocks makes no guarantees about the sequence in which threads trying to enter them are granted access.
- Therefore, if many threads are constantly competing for access to the same synchronized block, there is a risk that one or more of the threads are never granted access - that access is always granted to other threads. 
- This is called Starvation.
- To enable/guarantee fairness using lock, the code should look like the one shown below.
  public static void main() {
    Lock lock = new ReentrantLock(true);  // this overloaded method takes fairness (boolean) as it parameter
	lock.lock();
	// do something
	lock.unlock();
  }


Read/Write Locks:
-----------------
- Imagine you have an application that reads and writes some resource, but writing it is not done as much as reading it is. 
- Two threads reading the same resource does not cause problems for each other, so multiple threads that want to read the resource are granted access at the same time, overlapping. 
- But, if a single thread wants to write to the resource, no other reads nor writes must be in progress at the same time. 
- To solve this problem of allowing multiple readers but only one writer, you will need a read / write lock.

- condition for implementation:
  - Read Access: If no threads are writing, and no threads have requested write access.
  - Write Access: If no threads are reading or writing.


Reentrance Lockout:
-------------------
- Reentrance lockout may occur if a thread reenters a Lock, ReadWriteLock or some other synchronizer that is not reentrant.
- To avoid reentrance lockouts you have two options:
  - Avoid writing code that reenters locks
  - Use reentrant locks


Lock.lockInterruptibly():
-------------------------
Acquires lock only if the current thread which is trying to lock the lock is not interrupted.


Eg:
public static void lockInterruptibly() {
  Lock lock = new ReentrantLock();
  Thread.currentThread().interrupt();  // this statement is used to interrupt the current thread
  try {
    lock.lockInterruptibly();
	// do something..
	lock.unlock();
  } catch(InterruptedException e) {
    System.out.println("Thread interrupted");
  }
}


Lock.tryLock():
---------------
- Acquires lock only if it is free at the time.
- If lock is acquired, immediately returns true.
- If lock cannot be acquired, immediately returns false instead of waiting. Instead of waiting, the thread can do other operations.
Eg:
boolean isLockSuccessful = lock.tryLock();
boolean isLockSuccessful = lock.tryLock(2000, TimeUnit.MILLISECONDS);  // to guarantee fairness.


ReentrantLock methods:
----------------------
lock.getHoldCount();  // number of locks the current thread has locked
lock.getQueueLength();  // number of threads waiting in the queue for locking
lock.hasQueuedThread(Thread.currentThread());  // return if the given thread is queued to lock the lock
lock.hasQueuedThreads(); // returns if there is any thread queued to lock the lock
lock.isFair();
lock.isLocked();
lock.isHeldByCurrentThread();


Synchronized block vs Lock:
---------------------------
1. Synchronized blocks must be contained within a single method. lock() and unlock() can be in different methods.
2. Synchronized blocks are always reentrant. Lock can decide not to be.
3. Synchronized blocks do not guarantee fairness. Lock can.



ExecutorService:
================
- It is the Thread pool provided by java to which tasks can be submitted for concurrent execution.
- A simple example (with newFixedThreadPool method) is shown below.

  public class ExecutorServiceExample {
    public statis void main(String[] args) {
	  ExecutorService exService = Executors.newFixedThreadPool(10);  // creates a pool of 10 threads
	  
	  exService.execute(newRunnable("Task 1"));
	  exService.execute(newRunnable("Task 2"));
	  exService.execute(newRunnable("Task 3"));
	  
	  exService.shutdown();  // executor service shutdown
	}
	
	private static newRunnable(String msg) {
	  return new Runnable() {
	    public void run() {
		  String completeMsg = Thread.curentThread().getName() + ": " + msg;
		  System.out.println(completeMsg);
		}
	  }
	}
  }

  output:
  pool-1-thread-3: task 3
  pool-1-thread-1: task 1
  pool-1-thread-2: task 2


Types of ExecutorService:
=========================
SingleThreadExecutor:
---------------------
Runs single thread at a time to run any number of tasks. Ideal for less number of tasks.
Ensures that the tasks are executed sequentially.
Eg:
  ExecutorService exService = Executors.newSingleThreadExecutor();
  exService.execute(new Task1());
  exService.execute(new Thread(new Task2()));
  exService.shutdown();

FixedThreadPool:
----------------
- It runs fixed (input) number of threads at a given time. 
- It uses synchronous queue (like BlockingQueue) to hold the incoming tasks.
Eg1:
  ExecutorService exService = Executors.newFixedThreadPool(2);
  exService.execute(new Task1());
  exService.execute(new Task2());
  exService.execute(new Task3());
  exService.execute(new Task4());
  exService.execute(new Task5());
  exService.shutdown();

In the above example, task1 and task2 starts and only after it is completed, task3 and task4 starts and so on.


CachedThreadPool:
-----------------
- This type does not have fixed number of threads defined.
- It also does not use queue to hold the incoming tasks. However it uses synchronous queue which can hold only one task at a time.
- When the task arrives, it is stored in the queue and looks for any existing thread which is idle to execute task. If there is no existing thread, then it will create one for execution.
- Theoretically, it can create 1000 threads to execute tasks.
- If there is no taks to execute and if the thread is idle more than 60 seconds, it will be killed.

public static void main(String[] args) {
  // for lot of short lived tasks
  ExecutorService executorService = Executors.newCachedThreadPool();  // no argument passed
  
  // submit tasks for execution
  for(int i=0; i < 100; i++) {
    executorService.execute(new Task());
  }
}


ScheduledThreadPool:
--------------------
- Tasks can be executed in a scheduled time or after certain delay period.
- In fact, this class extends ScheduledExecutorService. 
- It used DelayQueue internally to store incoming tasks. Tasks are stored based on delay duration in ascending order.

  ScheduledExecutorService exService = Executors.newScheduledThreadPool(10);
  
Commonly used methods are:
- exService.schedule(new Task(), 10, TimeUnit.SECONDS):
  - Runs task after 10 seconds (a delay period mentioned).

- exService.scheduleAtFixedRate(new Task(), 15, 10, TimeUnit.SECONDS):
  - Runs task for every time interval.
  - Here it delays for 15 seconds for first task and for every 10 seconds, it runs subsequent task.

- exService.scheduleAtFixedDelay(new Task(), 15, 10, TimeUnit.SECONDS):
  - Runs task after certain period from previous task execution.
  - Here, it delays for 15 seconds for the first task and for the subsequent tasks, it delays for 10 seconds after completion of previous task.


ExecutorService - Constructor:
==============================

ExecutorService is an interface. It has 2 implementations.
1. ThreadPoolExecutor: Executes the tasks immediately as soon as they are submitted.
2. ScheduledThreadPoolExecutor: Tasks can be executed in a scheduled time. In fact, this class extends ScheduledExecutorService.

To create different type of thread pools as explained above, it uses static methods in Executors class. 
For example, ExecutorService exService = Executors.newSingleThreadExecutor();
These static methods internally uses ThreadPoolExecutor constructor (syntax below) to create thread pools as per configuration.

public ThreadPoolExecutor(int corePoolSize, int maxPoolSize, long keepAliveTime, TimeUnit unit, 
        BlockingQueue<Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) {
}

- corePoolSize:  Minimum/Base size of the pool
- maxPoolSize:  Maximum size of the pool
- keepAliveTime + unit:  Time to keep and idle thread alive (after which it is killed)
- workQueue:  Queue to store the tasks from which threads fetch them
- threadFactory:  The factory to use to create new threads
- handler:  Callback to use when tasks submitted are rejected

Note:
- At any time, the thread pool size will reduce below corePoolSize.
- allowCoreThreadTimeout(boolean value): can be used to define if the corePoolSize itself can be reduced.


- Eg:
  int corePoolSize = 10;  // base pool size
  int maxPoolSize = 20;  // if more tasks arrive, jvm can create additonal 10 threads
  long keepAliveTime = 3000;  // time after which the additional threads are removed if they are idle.
  
  ExecutorService tpe = new ThreadPoolExecutor(coolPoolSize, maxPoolSize, keepAliveTime, TimeUnit.MILLISECONDS, new ArrayBlockingQueue<>(128));


Runnable vs Callable:
=====================
- As we know the task that are created using Runnable interface, would override run() method. This method does not return any value.
- In cases, if we want the submitted tasks to return some value, we can used Callable interface.
- This interface contains call() method which return special type of value called Future.
- Future is value that will be returned at later point of time. So we can perform operation after the call() method is executed and before the actual value is expected to be returned.
- get() method is used to get the actual value from the Future object. An overloaded get(timePeriod, TimeUnit) method will wait for specified time and throw TimeoutException if the actual value is not returned.



ExecutorService execution methods:
==================================

executorService.execute():
--------------------------
- executes the task submitted in the form of Runnable.
- This method does not return any value.


executorService.submit(new Runnable()):
---------------------------------------
- executes the task submitted in the form of Runnable and returns Future.
- Future class contains isDone() and get() methods.
- the isDone() method is used to check if the execution is complete.
- the get() method is used to get the actual return value. This will block subsequent execution until the value is returned.
- Note that, since Runnable.run() method returns void, in practical, no value is returned (or returns null if attempted).
- Eg:
  public static void main(String[] args) {
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    Future futureObj = executorService.submit(newRunnable("Task 1"));
    furuteObj.get();
    System.out.println(furuteObj.isDone());

    executorService.shutdown();  // executor service shutdown
  }


executorService.submit(new Callable()):
---------------------------------------
- executes the task submitted in the form of Callable and returns Future.
- Future class contains isDone() and get() methods.
- the isDone() method is used to check if the execution is complete.
- The cancel() method is used to cancel the execution at any time.
- The isCancelled() method is used to check if the execution is cancelled.
- the get() method is used to get the actual return value. This will block subsequent execution until the value is returned.
- Eg:
  public static void main(String[] args) {
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    Future futureObj = executorService.submit(newCallable("Task 1"));
    furuteObj.get();
    System.out.println(furuteObj.isDone());

    executorService.shutdown();  // executor service shutdown
  }
	
  public static Callable newCallable(String msg) {
	return new Callable() {
      public Object call() {  
	    return Thread.currentThread().getName() + ": " + msg;  // return String value
	  }
    };
  }


executorService.invokeAny(Collection<new Callable()>):
------------------------------------------------------
- executes the tasks submitted in the form of Collection<Callable> and returns one of the value (first value). All other tasks will be cancelled.
- One of the use cases could be where you want faster response. Consider you want to access some information which is hosted in multiple servers. If one of them responds, the other requests can be cancelled.
- Eg:
    String result = executorService.invokeAny((Collection) callables);
	System.out.println(result);


executorService.invokeAll(Collection<new Callable()>):
------------------------------------------------------
- executes the tasks submitted in the form of Collection<Callable> and returns all of the values.
- Eg:
    List<Future<String>> results = executorService.invokeAll((Collection) callables);
	for(Future future: results) {  System.out.println(future.get());  }


ExecutorService other methods:
==============================

executorService.shutdown():
---------------------------
- This method will just initiate the shutdown process but not immediately.
- It will wait for tasks that are already submitted and/or has already started executing.
- If any task is submitted after calling shutdown() method, it will throw RejectedExecutionException.


executorService.isShutdown():
-----------------------------
- Will return true if the shutdown process is initiated.


executorService.isTerminated():
-------------------------------
- Will return true if the shutdown process is completed.


executorService.awaitTermination():
-----------------------------------
- In some cases, we would not want the service to wait for long time for task to complete.
- awaitTermination() method will block the shutdown process until either all tasks are completed or until the specified time.


executorService.shutdownNow():
------------------------------
- This method attempts to stop any currently running task (but not guaranteed).
- Then after the currently running task completes execution, the executor service will be shutdown.
- All other tasks waiting to get executed will be cancelled.


Cancel tasks via Future:
------------------------
- To cancel tasks submitted by Future using Callable implementation cancel() method is used.
- Eg:
  Future future = executorService.submit(newCallable("Task 1"));
  boolean mayInterrupt = true;
  future.cancel(mayInterrupt);
- In the above example, if the value passed to cancel() method is false, the tasks will not be cancelled.


Determining ideal number of Threads in ExecutorService:
=======================================================
The ideal number of Threads that can be created in ExecutorService or Multithreading environment depends on
1. Number of CPUs / CPU cores in the computer:
   - Ideally one CPU can run only one thread at a time. If it seems to run many threads, it is actually context switching.
   - In modern CPUs, there could be multiple cores. Each core can be considered as a single CPU.
   - However it must be noted that, even the operating system tasks might consume some CPU.

2. Type of work the thread performs:
   - If the task is CPU intensive, then keeping the thread count minimal is a good idea as they dont need switching.
   - But if the task does I/O operation at times, it is better to have multiple threads, so that when thread waiting for I/O operation to complete is waiting, another thread can start performing its task.

3. Desired fairness between threads:
   - Suppose one thread  keeps executing a task for very long time, then the other threads waiting for their turn has to wait for long time even the execute very small tasks.
   - It is then better to have few threads so that other threads get fairness.


ExecutorService using Virtual Threads:
======================================
- In Java 19 virtual threads were introduced. 
- They are light weight thread compared to traditional threads.

- Another way of creating ExecutorService apart from the ways discussed earlier is using Virtual Threads.

- Eg:
  ExecutorService executorService = Executors.newVirtualThreadTaskExecutor();

- Apart from using this method, everything remains the same.
- The executor's submit takes either Runnable or Callable as input.

- Though the Virtual Threads can be created directly, using ExecutorService has 2 reasons:
  - The application code has already been using ExecutorService all over and wanted to make use of it.
  - tasks can be submitted and future can be used.


CompletableFuture:
==================
Reference: https://www.youtube.com/watch?v=GJ5Tx43q6KM

Using CompletableFuture we can write asynchronous program (non-blocking code) where we can concurrently run N number of tasks in seperate thread without blocking main thread.

Drawbacks of using Future:
--------------------------
1. It cannot be completed/cancelled manually in the middle of its execution.
2. Multiple futures cannot be joined using builder methods.
3. Multiple futures cannot be combined together.
4. No proper exception handling mechanism.

Creating CompletableFuture:
---------------------------
CompletableFuture<String> compFuture = new CompletableFuture<>();
compFuture.get(); // this method call might take more time
compFuture.complete("returning some default value"); // this method call is used to complete a thread execution forcefully.


runAsync() and supplyAsync():
-----------------------------
runAsync():
-----------
If you want to run some background task asynchronously and DO NOT expect to return any value.
This method takes runnable and executor (optional) as argument(s).
It returns CompletableFuture<Void> as return type. 

Overloaded methods available are
01)  CompletableFuture.runAsync(Runnable)  // Takes the thread from ForkJoinPool provided by JVM
02)  CompletableFuture.runAsync(Runnable, Executor)  // Takes the thread from ExecutorService's pool that we pass

Example 1:
----------
  Executor myExecutor = Executors.newFixedThreadPool(3);
  CompletableFuture<Void> completableFutList = CompletableFuture
    .runAsync(() ->
	  {
	    System.out.println("Executed by " + thread.currentThread().getName());
		System.out.println(empList.size());
	  }, myExecutor);
	  
Example 2:
----------
Consider you want to read employee information from a json file and store it into DB. This does not return any value.

  public class RunAsyncDemo {
    public Void saveEmployees(File jsonFile) throws ExecutionException, InterruptedException {
      ObjectMapper mapper = new ObjectMapper();
  	  Executor myExecutor = Executors.newFixedThreadPool(3);
      CompletableFuture<Void> runAsyncFuture = CompletableFuture.runAsync(new Runnable() {
        public void run() {
          try {
            List<Employee> empList = mapper.readValue(jsonFile, new TypeReference<List<Employee>>() { });
            //write logic t save list of employee to database
            System.out.println("Thread : " + Thread.currentThread().getName());
            System.out.println(employees.size());
          } catch (IOException e) {  e.printStackTrace();  }
        }
      }, myExecutor);
  
      return runAsyncFuture.get();
    }
    
    public static void main(String[] args) throws ExecutionException, InterruptedException {
      RunAsyncDemo runAsyncDemo = new RunAsyncDemo();
      runAsyncDemo.saveEmployees(new File("employees.json"));
    }
  }
  

supplyAsync():
--------------
If you want to run some background task asynchronously and expect to return any value.
This method takes supplier and executor (optional) as argument(s).
It returns CompletableFuture<T> as return type, where T is the type of value obtained from supplier.

Overloaded methods available are 
03)  CompletableFuture.supplyAsync(Supplier)  // Takes the thread from ForkJoinPool provided by JVM
04)  CompletableFuture.supplyAsync(Supplier, Executor)  // Takes the thread from ExecutorService's pool that we pass

Example 1:
----------
  Executor myExecutor = Executors.newFixedThreadPool(3);
  CompletableFuture<List<Employee>> completableFutList = CompletableFuture
    .supplyAsync(() ->
	  {
	    System.out.println("Executed by " + thread.currentThread().getName());
		return EmployeeDatabase.getGetEmployees();
	  }, myExecutor);

Example 2:
----------
Consider you want to get the list of employees from the database for further processing.

public class SupplyAsyncDemo {

  public List<Employee> getEmployees() throws ExecutionException, InterruptedException {
    Executor myExecutor = Executors.newCachedThreadPool();
    CompletableFuture<List<Employee>> listCompletableFuture = CompletableFuture
      .supplyAsync(() -> {
        System.out.println("Executed by : " + Thread.currentThread().getName());
        return EmployeeDatabase.fetchEmployees();
        }
	  , myExecutor);
    return listCompletableFuture.get();
  }

  public static void main(String[] args) throws ExecutionException, InterruptedException {
    SupplyAsyncDemo supplyAsyncDemo = new SupplyAsyncDemo();
    List<Employee> employees = supplyAsyncDemo.getEmployees();
    employees.stream().forEach(System.out::println);
  }
}


Chaining the result of one CompletableFuture to another:
========================================================
Note:
- Function - Gets input and returns some data
- Consumer - Gets input and does not return anything
- Runnable - Gets input and does not return anything


If we want to chain multiple futures together (pass result of one method to another), we make use of these methods.
These methods execute the callback Synchronously. The ForkJoinPool thread provided by JVM is used.
05)  thenApply(Function)
06)  thenAccept(Consumer)
07)  thenRun(Runnable)


Runs the callback Asynchronously. The ForkJoinPool thread provided by JVM is used.
08)  thenApplyAsync(Function)
09)  thenAcceptAsync(Consumer)
10)  thenRunAsync(Runnable)


Runs the callback Asynchronously. The thread from the Executor Pool that we pass is used.
11)  thenApplyAsync(Function, Executor)
12)  thenAcceptAsync(Consumer, Executor)
13)  thenRunAsync(Runnable, Executor)


Example:
--------
Let us consider the scenario of sending email reminder to employees about pending trainings assigned to each of them.
The steps may look like one below:
  a. Get all employees from database.
  b. Filter out newly joined employees.
  c. Check if the status of any of the trainings is in pending status.
  d. Get/extract the email of the filtered employees from previous step.
  e. Send email notification to the employees.


public class EmployeeReminderService {

  public  CompletableFuture<Void> sendReminderToEmployee() {
    Executor myExecutor=Executors.newFixedThreadPool(5);

    CompletableFuture<Void> voidCompletableFuture = CompletableFuture
	  .supplyAsync(() -> {
          System.out.println("fetchEmployee : " + Thread.currentThread().getName());
          return EmployeeDatabase.fetchEmployees(); }, myExecutor)
	  .thenApplyAsync((employees) -> {
          System.out.println("filter new joiner employee  : " + Thread.currentThread().getName());
          return employees.stream()
            .filter(employee -> "TRUE".equals(employee.getNewJoiner()))
            .collect(Collectors.toList()); }, myExecutor)
	  .thenApplyAsync((employees) -> {
          System.out.println("filter training not complete employee  : " + Thread.currentThread().getName());
          return employees.stream()
            .filter(employee -> "TRUE".equals(employee.getLearningPending()))
            .collect(Collectors.toList()); }, myExecutor)
	  .thenApplyAsync((employees) -> {
          System.out.println("get emails  : " + Thread.currentThread().getName());
          return employees.stream()
		    .map(Employee::getEmail)
			.collect(Collectors.toList()); }, myExecutor)
	  .thenAcceptAsync((emails) -> {
          System.out.println("send email  : " + Thread.currentThread().getName());
          emails.forEach(EmployeeReminderService::sendEmail); }, myExecutor);
	  
      return voidCompletableFuture;
  }

  public static void sendEmail(String email) {
    System.out.println("sending training reminder email to : " + email);
  }

  public static void main(String[] args) throws ExecutionException, InterruptedException {
    EmployeeReminderService service=new EmployeeReminderService();
    service.sendReminderToEmployee().get();
  }
}


Combining the results of multiple CompletableFuture together:
=============================================================
There are different scenarios of combining CompletableFuture together.
14)  thenCompose() - Combining 2 dependent futures
15)  thenCombine() - Combining 2 independent futures
16)  allOf() - Combining multiple futures - wait for all of them
17)  anyOf() - Combining multiple futures - no need to wait for all of them. Get the result from the first future that completes the task.


Combining 2 dependent futures:
------------------------------
Consider we want to get an employee object based on certain condition and for that employee, we want to get the ratings.

Example:
--------
  public class CombineCompletableFutureDemo {

    public CompletableFuture<Employee> getEmployeeDetails() {
      return CompletableFuture.supplyAsync(() -> {
        System.out.println("getEmployeeDetails() " + Thread.currentThread().getName());
        return EmployeeDatabase.fetchEmployees()
          .stream().filter(emp -> "79-021-3776".equals(emp.getEmployeeId())).findAny().orElse(null);
      });
    }

    public CompletableFuture<Integer> getRatings(Employee employee) {
      return CompletableFuture.supplyAsync(() -> {
        System.out.println("getRatings() " + Thread.currentThread().getName());
        return employee.getRating();
      });
    }

    public static void main(String[] args) throws ExecutionException, InterruptedException {
      CombineCompletableFutureDemo cf = new CombineCompletableFutureDemo(); //employee -> ratings
      CompletableFuture<Integer> thenComposeResults = cf.getEmployeeDetails()
          .thenCompose(cf::getRatings);
      System.out.println("ratings : " + thenComposeResults.get());
	}

Combining 2 independent futures:
--------------------------------
Consider we have to call 2 different APIs, get their results and combine them. Note that, these APIs and their results are independent to each other.

Consider another example, where we want to group employees based on gender and get the count. Using another method, we want to get the email id of all employees. Finally combine both of them for further processing.

Example:
--------
  public static void main(String[] args) throws ExecutionException, InterruptedException {
    CompletableFuture<Map<String, Long>> employeeMapFuture = CompletableFuture
      .supplyAsync(() -> {
        return EmployeeDatabase.fetchEmployees()
          .stream()
          .collect(Collectors.groupingBy(Employee::getGender, Collectors.counting() ));
      });

    CompletableFuture<List<String>> emailsFuture = CompletableFuture
      .supplyAsync(() -> {
        return EmployeeDatabase.fetchEmployees()
          .stream().map(Employee::getEmail).collect(Collectors.toList());  });

    CompletableFuture<String> thenCombineResults = employeeMapFuture
	    .thenCombine(emailsFuture, (empMap, emails) -> empMap + " " + emails);
    System.out.println(thenCombineResults.get());
  }


Combining multiple futures - wait for all of them:
--------------------------------------------------
Consider in our application, we want to get different information from different APIs. For example, we want to fetch weather report, latest news and stock information from different APIs and combine them.
We can use allOf() method to achieve this.

Example:
--------
  public class MultiApiDataFetcher {

    public CompletableFuture<String> fetchWeatherData() {
      return CompletableFuture.supplyAsync(() -> {
        simulateDelay(2000); // Simulate network delay
        return "Weather: Sunny, 25°C";
      });
    }

    public CompletableFuture<String> fetchNewsHeadlines() {
      return CompletableFuture.supplyAsync(() -> {
        simulateDelay(3000); // Simulate network delay
        return "News: Java 23 Released!";
      });
    }

    public CompletableFuture<String> fetchStockPrices() {
      return CompletableFuture.supplyAsync(() -> {
        simulateDelay(1500); // Simulate network delay
        return "Stocks: AAPL - $150, GOOGL - $2800";
      });
    }

    private void simulateDelay(int millis) {
      try {
        Thread.sleep(millis);
      } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
    }

    public static void main(String[] args) {

      MultiApiDataFetcher fetcher = new MultiApiDataFetcher();
      CompletableFuture<String> weatherFuture = fetcher.fetchWeatherData();  //-> weatherDetailsAPI
      CompletableFuture<String> newsFuture = fetcher.fetchNewsHeadlines();  //-> news apis
      CompletableFuture<String> stockPriceFuture = fetcher.fetchStockPrices();  //-> stockPrice apis

      CompletableFuture<Void> allFutures = CompletableFuture.allOf(weatherFuture, newsFuture, stockPriceFuture);

      //process results after all future are completed
      allFutures.thenRun(() -> {
        String weather = weatherFuture.join();
        String news = newsFuture.join();
        String stock = stockPriceFuture.join();
		
		System.out.println("Aggregated Data : ");
        System.out.println(weather);
        System.out.println(news);
        System.out.println(stock);
      }).join();
    }
  }


Combining multiple futures - wait for one of them:
--------------------------------------------------
Consider our application is a stock exchange related. We fetch the stock price of companies from different reliable sources (APIs) and get the result from the one which responds first.
We can use anyOf() method to achieve this.


  public class StockPriceDataFetcher {

    public CompletableFuture<Double> fetchStockPriceFromApi1(String symbol) {
      return CompletableFuture.supplyAsync(() -> {
        simulateDelay(2000); // Simulate a delay of 2 seconds
        return 150.0; // Simulated stock price from API 1
      });
    }

    public CompletableFuture<Double> fetchStockPriceFromApi2(String symbol) {
      return CompletableFuture.supplyAsync(() -> {
        simulateDelay(1000); // Simulate a delay of 3 seconds
        return 155.0; // Simulated stock price from API 2
      });
    }

    private void simulateDelay(int millis) {
      try {
        Thread.sleep(millis);
      } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
    }

    public static void main(String[] args) {

      StockPriceDataFetcher fetcher = new StockPriceDataFetcher();
      String stockSymbol = "APPL"; //apple inc

      CompletableFuture<Double> api1Results = fetcher.fetchStockPriceFromApi1(stockSymbol);
      CompletableFuture<Double> api2Results = fetcher.fetchStockPriceFromApi2(stockSymbol);

      //Use anyOf to wait any of the future to complete
      CompletableFuture<Object> anyOfResults = CompletableFuture.anyOf(api1Results, api2Results);

      //process the result
      anyOfResults.thenAccept(price -> {  System.out.println("Stock price: $" + price);  }).join();
    }
  }


Exception Handling Strategy:
============================
In CompletableFuture, if the exception is not handled explicitly, the flow will be terminated and the subsequent future methods will not be executed.

We can handle exception in 2 ways.
1. Handle individually for each future method calls.
2. Handle globally.


Handling Individually (using '.exceptionally()'):
-------------------------------------------------
public class ExceptionHandlingUsecase {

    public static void main(String[] args) throws ExecutionException, InterruptedException {

      // update employee DB
      CompletableFuture<String> employeeDataFuture = CompletableFuture.supplyAsync(() -> {
          gracefullyShutDown("Storing Employee information in DB");
          return "Employee information update in DB";
        })
        .exceptionally(ex -> {
          System.out.println("unable to update employee information in DB");
          return "500 Internal Server Error";
        });

      CompletableFuture<String> employeeDocumentFuture = CompletableFuture
        .supplyAsync(() -> {
          //gracefullyShutDown("Uploading Employee document into S3");
          return "Employee document update in S3";
        });
        // .exceptionally(ex -> {
        //   System.out.println("unable to update employee document in s3");
        //   return "500 Internal Server Error";
        // });

        //flow 3

        //flow 4

      CompletableFuture<String> combineFuture = employeeDataFuture
        .thenCombine(employeeDocumentFuture, (result1, result2) -> {
          return result1 + "\n" + result2;
        });

      System.out.println(combineFuture.get());
    }

    private static void gracefullyShutDown(String apiName) {
      throw new RuntimeException(apiName + " service temporarily unavailable. Please try again later.");
    }
  }


Handling Globally (using '.handle()'):
--------------------------------------
  public class ExceptionHandlingUsecase {

    public static void main(String[] args) throws ExecutionException, InterruptedException {

      // update employee DB
      CompletableFuture<String> employeeDataFuture = CompletableFuture
        .supplyAsync(() -> {
          gracefullyShutDown("Employee");
          return "Employee information update in DB";
        });

      CompletableFuture<String> employeeDocumentFuture = CompletableFuture
        .supplyAsync(() -> {
          //gracefullyShutDown("S3");
          return "Employee document update in S3";
        });

        //flow 3

        //flow 4

      CompletableFuture<String> combineFuture = employeeDataFuture
        .thenCombine(employeeDocumentFuture, (result1, result2) -> {
          return result1 + "\n" + result2;
        })
              
        .handle((res, ex) -> {  //Global Exception Handling
          if (ex != null) {
            System.out.println("An error occurred during processing employee data " + ex.getMessage());
            return "Operation Failed ! ";
          }
            return res;  // if exception is not thrown, return the actual result
          });

      System.out.println(combineFuture.get());
    }

    private static void gracefullyShutDown(String apiName) {
      throw new RuntimeException(apiName + " service temporarily unavailable. Please try again later.");
    }
  }



Deadlock in Java:
=================

What is Deadlock:
-----------------
- A deadlock is when two or more threads are blocked waiting to obtain locks that some of the other threads in the deadlock are holding. 
- Deadlock can occur when multiple threads need the same locks, at the same time, but obtain them in different order.

Below is an example of a deadlock situation:

- If Thread 1 locks lock-A, and tries to lock lock-B, and Thread 2 has already locked lock-B, and tries to lock lock-A, a deadlock arises.
- Thread 1 can never get B, and Thread 2 can never get A. 
They will remain blocked on each their object, A and B, forever. In fact, neither of them will ever know.


A simple example:
-----------------
Let us implement 2 classes Runnable1 and Runnable2 which does operation in following sequence.
Runnable1 - locks Lock1, waits for 3 seconds, locks Lock2.
Runnable1 - locks Lock2, waits for 3 seconds, locks Lock1.

public class Runnable1 implements Runnable {
  private Lock lock1 = null;
  private Lock lock2 = null;
  
  public Runnable1(Lock lock1, Lock lock2) {
    this.lock1 = lock1;
	this.lock2 = lock2;
  }

  public void run() {
    String threadName = Thread.currentThread().getName();
	System.out.println(threadName + " attempting to lock Lock1");
	lock1.lock();
	System.out.println(threadName + " locked Lock1");
	
	try {
	  Thread.sleep(3000);  // this is to explicitly create a deadlock situation
	} catch(InterruptedException ie) { .... }
	
	System.out.println(threadName + " attempting to lock Lock2");
	lock2.lock();
	System.out.println(threadName + " locked Lock2");
	
	// do actual work assuming both locks were acquired
	
	System.out.println(threadName + " unlocking Lock1");
	lock1.unlock();
	System.out.println(threadName + " unlocking Lock2");
	lock2.unlock();
  }
}


Deadlock in two synchronized blocks:
------------------------------------
- Deadlock occurs not only with Locks, but also with synchronized blocks.

public class RunnableSync1 implements Runnable {
  private Object lock1 = null;
  private Object lock2 = null;
  
  public Runnable1(Object lock1, Object lock2) {
    this.lock1 = lock1;
	this.lock2 = lock2;
  }

  public void run() {
    String threadName = Thread.currentThread().getName();
	System.out.println("threadName + " attempting to lock Lock1");
	synchronized(lock1) {
	  System.out.println("threadName + " locked Lock1");
	
	  try {
	    Thread.sleep(3000);  // this is to explicitly create a deadlock situation
	  } catch(InterruptedException ie) { .... }
	
	  System.out.println("threadName + " attempting to lock Lock2");
	  synchronized(lock2) {
	    System.out.println("threadName + " locked Lock2");
	
	    // do actual work assuming both locks were acquired
	
	    System.out.println("threadName + " unlocking Lock1");
	  }
	  System.out.println("threadName + " unlocking Lock2");
	}
  }
}


- In the above examples, deadlock can be easily fixed by reordering the sequence of locking.
- However, due to the underlying business logic it may not be ideal solution.


Complex Deadlock scenario:
--------------------------
- In practical, there could be cases where threads intended to perform some action(s) need to acquire multiple locks.
- Sometimes, the order in which the locks are acquired are determined at runtime. In that case, lock reordering will not be possible.
- Consider the following example.
  - Thread 1 tries to acquire locks in the sequence, lock1, lock2, lock3, lock4, lock5, lock6.
  - Thread 2 tries to acquire locks in the sequence, lock4, lock5, lock6, lock1, lock2, lock3.
  - By the time Thread 1 trying to acquire lock4 and Thread 2 would have already acquired it. Similarly, when Thread 2 tries to acquire lock1 and Thread 1 would have already acquired it.

- A deadlock will block all threads trying to acquire any lock which is part of deadlock.


Other problems similar to Deadlock:
-----------------------------------
There could be other phenomenon similar to Deadlock which causes thread to wait indefinitely.
- Livelock:
  - The case where thread are trying to resolve existing deadlock indefinitely which results in new deadlock.
- Nested Monitor Lockout:
- Reentrance Lockout:
- Starvation:
  - Case where a thread is put back in the queue so that it waits indefinitely to try acquiring lock.


Deadlock Prevention:
====================
Below are some common deadlock prevention and detection techniques.

- Lock reordering:
  - Deadlock occurs when multiple threads need the same locks but obtain them in different order.
  - If we make sure that all locks are always taken in the same order by any thread, deadlocks cannot occur.

- Timeout backoff:
  - Here a thread trying to obtain a lock will only try for certain period of time before giving up.
  - If a thread does not succeed in taking all necessary locks within the given timeout, it will backup, free all locks taken, wait for a random amount of time and then retry. 
  - This random duration is defined in the code itself and the thread waits to give other threads a chance to take all locks.
  - Note that just because a lock timesout it does not necessarily mean that the threads had deadlocked. It could also just mean that the thread holding the lock (causing the other thread to time out) takes a long time to complete its task.
  - A better option is to assign a priority of the threads so that only one (or a few) thread backs up. The rest of the threads continue taking the locks they need as if no deadlock had occurred. If the priority assigned to the threads is fixed, the same threads will always be given higher priority. To avoid this you may assign the priority randomly whenever a deadlock is detected.
  - An example flow is shown below:
      Thread 1 locks A
      Thread 2 locks B

      Thread 1 attempts to lock B but is blocked
      Thread 2 attempts to lock A but is blocked

      Thread 1's lock attempt on B times out
      Thread 1 backs up and releases A as well
      Thread 1 waits randomly (e.g. 257 millis) before retrying.

      Thread 2's lock attempt on A times out
      Thread 2 backs up and releases B as well
      Thread 2 waits randomly (e.g. 43 millis) before retrying.

- Deadlock detection:
  - Deadlock detection can be used in cases where lock ordering and lock timeout isn't possible.
  - Every time a thread takes a lock it is noted in a data structure (map, graph etc.) of threads and locks. Additionally, whenever a thread requests a lock this is also noted in this data structure.
  - When a thread requests a lock but the request is denied, the thread can traverse the lock graph to check for deadlocks. For instance, if a Thread A requests lock 7, but lock 7 is held by Thread B, then Thread A can check if Thread B has requested any of the locks Thread A holds (if any). If Thread B has requested so, a deadlock has occurred (Thread A having taken lock 1, requesting lock 7, Thread B having taken lock 7, requesting lock 1).


BlockingQueue:
==============
- It is an interface which is used to store elements.
- Java Queues are used to Enqueue elements at the end and Dequeue elements at the beginning.

- Using BlockingQueue, we can add tasks until there is a free space available. At the same time, until there is atleast one element, the threads can consume them and process further.
- There are many implementations of the interface which can be used based on requirement.
  - ArrayBlockingQueue
  - DelayQueue
  - LinkedBlockingQueue
  - PriorityBlockingQueue
  - SynchronousQueue
  - LinkedTransferQueue
  - DelayDequeue
  - LinkedBlockingDequeue

BlockingQueue example:
----------------------
  public class BlockingQueueExample {
    pubic static void main(String[] args){
      BlockingQueue<String> bQueue = new ArrayBlockingQueue<>(3);  // defines a String generic BlockingQueue
	
	  bQueue.put("element 1");  // keep adding elements
	  bQueue.put("element 2");
	
	  System.out.println(bQueue.take());  // keep reading elements from first element avaialble
	  System.out.println(bQueue.take());
    }
  }

Producer-Consumer Example:
--------------------------
Let us now see a practical example of BlockingQueue.

Producer class:
---------------
public class MyProducer implements Runnable {
  BlockingQueue<String> bQueue = null;
  public MyProducer(BlockingQueue<String> queue){
    this.bQueue = queue;
  }
  
  public void run() {
    while(true) {  // some valid condition. eg: until there is some space to add message/tasks
	  long timeMillis = System.currentTimeMillis();
	  try {
	    this.bQueue.put("" + timeMillis);
	  } catch(InterruptedException ie) {
	    System.out.println("Producer was interrupted");
	  }
	  Thread.sleep(1000);
	}
  }
}

Consumer class:
---------------
public class MyConsumer implements Runnable {
  BlockingQueue<String> bQueue = null;
  public MyConsumer(BlockingQueue<String> queue){
    this.bQueue = queue;
  }
  
  public void run() {
    while(true) {  // some valid condition. eg: when there is atleast one task/message available in the queue
	  try {
	    String element = this.bQueue.take();
	    System.out.println("Consumed :" + element);
	  } catch(InterruptedException ie) {
	    System.out.println("Consumer was interrupted");
	  }
	}
  }
}

BlockingQueueImplementation.java:
---------------------------------
public class BlockingQueueImplementation {
  public static void main(String[] args) {
    BlockingQueue<String> bQueue = new ArrayBlockingQueue<>(3);
	
	MyProducer myProducer = new MyProducer(bQueue);
	MyConsumer myConsumer = new MyConsumer(bQueue);
	
	Thread producerThread = new Thread(myProducer);
	Thread consumerThread = new Thread(myConsumer);
	producerThread.start();
	consumerThread.start();
  }
}


BlockingQueue commonly used methods:
------------------------------------
Methods to add elements:
------------------------
blockingQueue.put():
  - bQueue.put("1");
  - It will put the specified element in the queue. 
  - But it will be blocked until there is space inside the queue (if the queue was full).
  - It will throw InterruptedException if the thread that is blocked to put element is interrupted.

blockingQueue.add():
  - blockingQueue.add("2");
  - It will not block if there is no space in the queue. Instead, it will throw IllegalStateException if no space is available.

blockingQueue.offer():
  - boolean wasEnqueued = blockingQueue.offer("3");
  - If the queue is full, it will neither block nor IllegalStateException. Instead, it will return false if no space.

blockingQueue.offer(Object, time, TimeUnit):
  - blockingQueue.offer("4", 1000, TimeUnit.MILLISECONDS);
  - If the queue is full, it will wait for specified time and then returns false if the queue is still full and unable to enqueue element.
  - It will be blocked until the specified time or if a free space is available in the queue. 
  - It will throw InterruptedException if the thread that is blocked to put element is interrupted.


Methods to get elements from queue:
-----------------------------------
blockingQueue.take():
  - bQueue.take();
  - It will dequeue element from the queue. 
  - But it will be blocked until an element is available in the queue. 
  - It will throw InterruptedException if the thread that is blocked to take element(s) is interrupted.

blockingQueue.poll():
  - String element = blockingQueue.poll();
  - returns null if there is no element avaliable in the queue.


blockingQueue.poll(time, TimeUnit):
  - blockingQueue.poll(1000, TimeUnit.MILLISECONDS);
  - If the queue is empty, it will wait for specified time and then returns null if the queue is still empty and unable to dequeue element.
  - It will be blocked until an element is available in the queue or until the specified time. 
  - It will throw InterruptedException if the thread that is blocked to put element is interrupted.

blockingQueue.remove():
  - blockingQueue.remove("1");
  - removes the element specified if present in the queue.
  - returns boolean value based on the operation.


blockingQueue.drainTo():
  - Collection dest = new ArrayList();    blockingQueue.drainTo(dest);
  - It will drain/extract and put all the elements to the collection passed as argument.

blockingQueue.drainTo():
  - Collection dest = new ArrayList();    blockingQueue.drainTo(dest, 5);
  - It will drain/extract and put specified number of elements to the collection passed as argument. If available_no_of_elements < specified_no_of_elements, it will extract all the elements.


blockingQueue.peek():
  - blockingQueue.peek();
  - To read the element from the queue but does not remove it.
  - If there is no element in the queue, it will return null.

blockingQueue.element():
  - blockingQueue.element();
  - To read the element from the queue but does not remove it.
  - If there is no element in the queue, it will throw NoSuchElementException.


blockingQueue.size():
  - int size = blockingQueue.size();

blockingQueue.remainingCapacity():
  - int capacity = blockingQueue.remainingCapacity();
  - returns remaining free space.

blockingQueue.contains():
  - boolean hasElement = blockingQueue.contains("1");
  - Uses equals method to perform the operation.


ArrayBlockingQueue:
===================
- ArrayBlockingQueue (implementation of BlockingQueue) is a bounded, blocking queue that stores the elements internally in an array.
- This means there is an upper bound on the number of elements it can store at the same time.
- It stores the elements internally in FIFO (First In, First Out) order. 
- The element in the head of the queue survives the longest time, and the element in the tail of the queue survives the shortest time.

LinkedBlockingQueue:
====================
- The LinkedBlockingQueue (implementation of BlockingQueue) keeps the elements internally in a linked structure (linked nodes).
- This linked structure can optionally have an upper bound if desired. If not specified, Integer.MAX_VALUE is the upper bound.
- It stores the elements internally in FIFO (First In, First Out) order. 
- The element in the head of the queue survives the longest time, and the element in the tail of the queue survives the shortest time.

PriorityBlockingQueue:
======================
- The PriorityBlockingQueue (implementation of BlockingQueue) is an unbounded concurrent queue.
- It uses the same ordering rules as the java.util.PriorityQueue class. You cannot insert null into this queue.
- All elements inserted into the PriorityBlockingQueue must implement the java.lang.Comparable interface. The elements thus order themselves according to whatever priority you decide in your Comparable implementation.
- Notice that the PriorityBlockingQueue does not enforce any specific behaviour for elements that have equal priority (compare() == 0).
- Also notice, that in case you obtain an Iterator from a PriorityBlockingQueue, the Iterator does not guarantee to iterate the elements in priority order.

SynchronousQueue:
=================
- The SynchronousQueue is a queue that can be used to exchange a single element with another thread.
- A thread inserting an element into the queue is blocked until another thread takes that element from the queue.
- Likewise, if a thread tries to take an element and no element is currently present, that thread is blocked until a thread insert an element into the queue.

BlockingDeque:
==============
- A Deque (Double Ended Queue) is a queue which can insert and take elements from, from both ends.
- A BlockingDeque could be used if threads are both producing and consuming elements of the same queue.
- It could also just be used if the producting thread needs to insert at both ends of the queue, and the consuming thread needs to remove from both ends of the queue.
- If the deque is full, the inserting thread will be blocked until a removing thread takes an element out of the deque.
- If the deque is empty, a removing thread will be blocked until an inserting thread inserts an element into the deque.


Choosing appropriate queues based on the ThreadPool type:
---------------------------------------------------------
LinkedBlockingQueue:
--------------------
- FixedThreadPool and SingleThreadExecutor have fixed number of threads defined. 
- So it cannot have Queue whose size is also fixed. In other words, the unbounded queue is used to store tasks.
- Since queu can never become full, new threads are never created.

SynchronousQueue:
-----------------
CachedThreadPool will create new thread dynamically and delete when not required. So it does not need to store tasks. For this, SynchronousQueue is used.

ScheduledThreadPool:
--------------------
As ScheduledThreadPool executes tasks are per their scheduled time, special type of queue called DelayedWorkQueue is used. 

Custom ThreadPool:
------------------
Bounded queue like ArrayBlockingQueue is used to store the tasks.
If the queue becomes full, new thread is created (as long as count is less than maxPoolSize).



Producer Consumer Pattern:
==========================
Introduction:
-------------
- It is the pattern in which the Work Detecting Threads (Producers) and Work Executing Threads (Consumers) are decoupled yet work together.
- Decoupling means you can control how many threads at a time that are engaged in detecting or executing the work.
- There could be some scenarios where this pattern can be useful.
  - If we have to read a directory in a server and process it based on some pre-condition. If same set of threads perform both pre-condition check and actual processing, it might become slow eventually.

Use cases:
----------
1. Reduce foreground thread latency:
------------------------------------
- Consider a Graphical User Interface. The application has to perform some graphics action when the data is submited to the server.
- So if both actions (graphics action, actual processing at the server end) are performed by same set of threads, then at some point of time, the system will start responding slowly.
- But offloading the graphics action from background tasks, we can achieve better performance.
1

2. Load balance between worker threads:
---------------------------------------
- Consider an application that accepts connections from various remote servers, parse/transform information and do some heavy processing at the background.
- Again, if all the steps were processed by same set of thread it would not be efficient.
- In the above examples, we do not have to do anything to acheive load balancing. In fact, it comes in-house with Producer Consumer pattern. 


3. Backpressure management:
---------------------------
- If the queue between the producer and consumer threads is a BlockingQueue, then you can use the queue for backpressure management.
- This is another built-in feature of the producer consumer pattern.

- Backpressure means, that if producer thread(s) produce more work than consumer threads can process, the tasks will queue up in the queue.
- At some point the queue will become full, and producer threads will be blocked to insert new tasks into the queue.
- This phenomenon is called backpressure.

Producer Consumer Example:
--------------------------

 public class ProducerConsumerExample {
   public static void main(String[] args) {
     BlockingQueue<String> bQueue = new ArrayBlockingQueue<>(3);
	 
	 Producer producer = new Producer(bQueue);
	 Consumer consumer1 = new Consumer(bQueue);
	 Consumer consumer2 = new Consumer(bQueue);
	 
	 Thread producerThread = new Thread(producer);
	 Thread consumerThread1 = new Thread(consumer1);
	 Thread consumerThread2 = new Thread(consumer2);
	 
	 producerThread.start();
	 consumerThread1.start();
	 consumerThread2.start();
   }
 }


  public class Producer implements Runnable {
    BlockingQueue<String> bQueue = null;

    public Producer(BlockingQueue<String> queue){
      this.bQueue = queue;
    }
    
    public void run() {
      while(true) {
  	    long timeMillis = System.currentTimeMillis();
  	    try {
  	      this.bQueue.put("" + timeMillis);
  	    } catch(InterruptedException ie) {
  	      System.out.println("Producer was interrupted");
  	    }
  	    Thread.sleep(1000);
  	  }
    }
  }
  
  public class Consumer implements Runnable {
    BlockingQueue<String> bQueue = null;

	public Consumer(BlockingQueue<String> queue){
      this.bQueue = queue;
    }
    
    public void run() {
      while(true) {
  	    try {
  	      String element = this.bQueue.take();
		  String text = Thread.currentThread().getName() + " consumed " + element;
  	      System.out.println(text);
  	    } catch(InterruptedException ie) {
  	      e.printStackTrace();
  	    }
  	  }
    }
  }



Compare and Swap:
=================
Introduction:
-------------
- Compare and Swap compares the value of a variable with an expected value, and if they are equal then swaps the value of the variable for a new value.
- The the caller of the method will get a boolean signal (true/false) based on the outcome.

Compare and Swap for Check Then Act Cases:
------------------------------------------
- The check then act pattern occurs when the code first checks the value of a variable and then acts based on that value.
- An example is shown below which is explained later.

public class ProblematicLock {
  private volatile boolean locked = false;

  public void lock() {
    while(this.locked) {
	  // busy wait - until this.locked == false
	}
    this.locked = true;
  }

  public void unlock() {  this.locked = false;  }
}

- The lock() method first checks if the member variable 'locked' is equal to false (inside while loop). 
- If it is false, the lock() method leaves the while loop and sets locked to true. 
- In other words, the lock() method first checks the value of the locked variable, and then acts based on that check.
- If multiple threads had access to the same instance, the above lock() method would not be guaranteed to work as intended.
  - For example, If thread A checks the value of locked and sees that it is false (expected value), it will exit the while-loop to act upon that check. If thread B also checks the value of locked before thread A sets the value of locked to true, then thread B will also exit the while-loop to act upon that check. This is a classical race condition.
- To avoid this problem, Check Then Act must Be Atomic (non-dividable).
- A simple way to make a block of Java code atomic is to mark the method with synchronized.

Blocking Threads is Expensive:
------------------------------
- Entering a synchronized block is not that expensive. But if the thread is blocked because another thread is already executing inside the synchronized block, the blocking of the thread is expensive.
- Also, It is typically upto the OS or the execution platform to determine when a blocked thread is unblocked when the synchronized block is free again.

Atomic Compare And Swap Operations:
-----------------------------------
- Modern CPUs have built-in support for atomic compare and swap operations.
- The CPU guarantees that only one thread can execute a compare-and-swap operation at a time, even across CPU cores.
- When using this approach, the OS or execution platform does not need to handle the blocking/unblocking of threads. 
- This results in shorter amounts of time where a thread waits to execute a compare-and-swap operation resulting in higher throughput.

Compare And Swap as Guard:
--------------------------
public class CompareAndSwapLock {
  private AtomicBoolean locked = new AtomicBoolean(false);

  public void unlock() {
    this.locked.set(false);
  }

  public void lock() {
    while(!this.locked.compareAndSet(false, true)) {
	  // busy wait - until compareAndSet() succeeds
	}
  }
}

- Notice the locked variable is no longer a boolean but an AtomicBoolean.
- In the example above the compareAndSet() method compares the value of locked to false. If so it sets the new value of the AtomicBoolean to true.



Atomic Classes:
===============
The Lock class provides a better solution than synchronizing methods.
However, the increment operation is still not atomic. For this, we have a feature called Atomic classes.
Using this class we can make the operation atomic.
public class Counter{
  private AtomicInteger count = new AtomicInteger();
  public void increment{
    count.incrementAndGet();
  }
  public int getCount(){
    return count;
  }
}

Atomic class support data types like int, long, float etc.
However, if we want to add thread safety to your custom objects we should use one of the previous approaches.


False Sharing:
==============

Introduction:
-------------
- False sharing occurs when two threads running on two different CPUs/Cores write to two different variables which are stored within the same CPU cache line. 
- When the first thread modifies one of the variables - the whole CPU cache line is invalidated in the CPU caches of the other CPU where the other thread is running.
- So the other CPUs need to reload the content of the invalidated cache line, even if they don't need the variable that was modified within that cache line.


Cache Lines:
------------
- When the CPU caches are reading data from lower level caches or main RAM (e.g. L1 from L2, L2 from L3 and L3 from main RAM), they don't just read a single byte at a time which would be inefficient.
- Instead they read an entire cache line. A cache line typically consists of 64 bytes (might vary based on the hardware used).

- Because a cache line consist of multiple bytes, a single cache line will often store more than one variable. 
- If the same CPU needs to access more of the variables stored within the same cache line - this is an advantage. 
- If multiple CPUs need to access the variables stored within the same cache line, false sharing can occur.


Cache Line Invalidation:
------------------------
- When a CPU writes to memory address in a cache line, typically because the CPU is writing to a variable, the cache line becomes dirty.
- The cache line then needs to be synchronized to other CPUs that also have that cache line in their CPU caches.
- The same cache line stored in the other CPU caches thus becomes invalid - they need to be refreshed, in other words.
- Cache refreshing after cache invalidation can happen either via cache coherence mechanisms, or by reloading the cache line from main RAM.


False Sharing results in a Performance degratation:
---------------------------------------------------
- Since the cache needs to be refreshed for every change in the variable's value, this results in a performance degradation.


Example:
The following two classes illustrate how false sharing can occur in a Java application.

public class Counter {

    public volatile long count1 = 0;
    public volatile long count2 = 0;

}

public class FalseSharingExample {

  public static void main(String[] args) {

    Counter counter1 = new Counter();
    Counter counter2 = counter1;

    long iterations = 1_000_000_000;

    Thread thread1 = new Thread(() -> {
      long startTime = System.currentTimeMillis();
      for(long i=0; i<iterations; i++) {  
        counter1.count1++;
      }
      long endTime = System.currentTimeMillis();
      System.out.println("total time: " + (endTime - startTime));
    });
    Thread thread2 = new Thread(() -> {
      long startTime = System.currentTimeMillis();
      for(long i=0; i<iterations; i++) {
        counter2.count2++;
      }
      long endTime = System.currentTimeMillis();
      System.out.println("total time: " + (endTime - startTime));
    });

    thread1.start();
    thread2.start();
  }
}

- In the above example, two threads increments the two counter fields within the same Counter instance.
- To overcome false sharing, we can make each thread increment the fields of two different Counter instances.
- However this is not the right fix. Instead we can use @Contented annotation.


@Contented:
-----------
- From Java 8 and 9, we can pad fields inside classes with empty bytes, so that the fields inside an object of that class are not stored within the same CPU cache line.

- Annotating the field with @Contented will make the target field to be stored in different cache line as that of other fields of the class.
  public class Counter1 {
    @jdk.internal.vm.annotation.Contended
    public volatile long count1 = 0;
    public volatile long count2 = 0;
  }

- Annotating the class with @Contented will make each of the class' field to be stored in different cache lines.
  @jdk.internal.vm.annotation.Contended
  public class Counter1 {
    public volatile long count1 = 0;
    public volatile long count2 = 0;
	public volatile long count3 = 0;
  }
- The @Contended annotation makes it possible to group fields so each grouped fields are kept close together in RAM, but have padding between fields of other groups.
  public class Counter1 {
  @jdk.internal.vm.annotation.Contended("group1")
    public volatile long count1 = 0;
	
	@jdk.internal.vm.annotation.Contended("group1")
    public volatile long count2 = 0;
	
	@jdk.internal.vm.annotation.Contended("group2")
	public volatile long count3 = 0;
  }


Configuring the Padding Size:
-----------------------------
- By default the @Contended annotation adds 128 bytes of padding after a field annotated with @Contended.
- However, it can be configured in JVM command line parameter.
    -XX:ContendedPaddingWidth=64



Single-threaded and Same-threaded designs:
==========================================



Thread Congestion:
==================
- Thread congestion occurs when multiple thread tries to access same blocking data structure (Blocking Queue) at the same time.
- For example, if consumer thread C1 is accessing the data structure, then consumer threads C2,.. will be blocked and has to wait for the data structure to be available. Also, if a producer thread P1 uses the queue to put some element, all the consumer threads will be blocked.
- More the number of threads queued up, higher the level of thread congestion.

Example:
  public class ThreadCongestionExample {
    public static void main(String[] args) {
	  int objectsToProduce = 1_000_000;
	  
	  BlockingQueue<String> bQueue = new ArrayBlockingQueue<>(objectsToProduce);
	  
	  ConsumerRunnable[] runnables = new ConsumerRunnable[3];
	  
	  synchronized(ThreadCongestionExample.class) {
	    for(int i=0; i<runnables.length; i++) {
		  runnables[i] = new ConsumerRunnable(bQueue);
		  Thread consumingThread = new Thread(runnables[i]);
		  consumingThread.start();
		}
	  }
	  
	  Thread producingThread = new Thread({
	    for(int i=0; i<objectsToProduce; i++) {
		  try {
		    bQueue.put("" + i);
		  } catch(InterruptedException ie) {
		    ie.printStackTrace();
		  }
		}
		
		System.out.println("All objects produced");
		System.out.println("=> produced " + objectsToProduce);
		synchronized(ThreadCongestionExample.class) {
		  for(int i=0; i<runnables.length; i++) {
		    runnables[i].stop();
		  }
		}
	  });
	  producingThread.start();
	}
  }

- One way to avoid thread congestion is the use number of Blocking Queues equal to number of consumer threads. This may not be always possible, but if possible, it can be implemented.
- However, this solution can lead to situation when one of the queues become empty while other still have element to process. At this time, the thread will be blocked waiting for new element to be inserted. One solution for this is to allow the thread to steal element from the other queue and process it.

Ways to detect thread congestion:
---------------------------------
- Detecting thread congestion could be tricky as this happens within JVM.
- One way is to use Profiler
- Another way is to start the thread count from 1 and keep increasing until the execution time comes to a point from where it does not improve further.


Thread Signaling (wait(), notify(), notifyAll()):
==================================================
- Thread signaling is used to execute tasks by coordinating between multiple threads.
- The method from java.lang.Object class namely wait(), notify(), notifyAll() are used for this.
- When a thread calls wait() method on an object, it is paused until it is interrupted or some other thread calls notify() or notifyAll().
- Below is an example class that can be used for two threads to pass signals.

public class MonitorObject{  }

public class MyWaitNotify{
  MonitorObject myMonitorObject = new MonitorObject();

  public void doWait(){
    synchronized(myMonitorObject){
      try{
        myMonitorObject.wait();
      } catch(InterruptedException e){...}
    }
  }

  public void doNotify(){
    synchronized(myMonitorObject){
      myMonitorObject.notify();
    }
  }
}

- These 3 methods must be called only within synchronized context (i.e. with synchronized block or method). 
- Also wait() method releases the lock for other objects to acquire it.
- When the notify() method is called, the thread in waiting state is moved to runnable state. This means it does not guarantee that the thread that was waiting will resume execution unless there is another thread that has already entered the synchronized block on the same object.


Missed Signals:
===============
- If a thread calls notify() before the thread to signal has called wait(), the signal will be missed by the waiting thread. 
- This may result in the waiting thread waiting forever, never waking up, because the signal to wake up was missed.
- To avoid this problem, the notify signal should be stored in a member variable inside the class' instance.

public class MyWaitNotify2{

  MonitorObject myMonitorObject = new MonitorObject();
  boolean wasSignalled = false;

  public void doWait(){
    synchronized(myMonitorObject){
      if(!wasSignalled){
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }

  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}


- Notice how the doNotify() method now sets the wasSignalled variable to true before calling notify().
- Also, notice how the doWait() method now checks the wasSignalled variable before calling wait(). In fact it only calls wait() if no signal was received in between the previous doWait() call and this.


Spurious Wakeups:
-----------------
- For inexplicable reasons it is possible for threads to wake up even if notify() and notifyAll() has not been called. This is known as spurious wakeups.
- To guard against spurious wakeups the signal member variable is checked inside a while loop instead of inside an if-statement. Such a while loop is also called a spin lock.
- The thread awakened spins around until the condition in the spin lock (while loop) becomes false.

public class MyWaitNotify3{

  MonitorObject myMonitorObject = new MonitorObject();
  boolean wasSignalled = false;

  public void doWait(){
    synchronized(myMonitorObject){
      while(!wasSignalled){
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }

  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}


ForkJoinPool in Java:
=====================
- In Java, ForkJoinPool is used to break single big task into smaller tasks and execute them in parallel.
- Each task can be executed by seperate Thread which may run in different CPUs or CPU cores.
- The tasks can be divided recursively until the tasks cannot be logically divided further.
- In ForkJoin, there are 2 phases involved.
  - In Fork phase the tasks are divided into many subtasks.
  - In Join phase, each subtasks' result will be joined to its parent task up till the main task.

- ForkJoinPool uses work stealing internally to utilize the resource efficiently.
- Consider there are 2 threads T1 and T2 which have their own set of tasks to be executed and stored in the queue.
- When one of the threads finished executing all the tasks assigned to it, it does not become idle. Instead it takes the tasks one by one from the other queue from the tail and starts executing.

- Let us now see a simple implementation of ForkJoinPool.

import java.util.concurrent.ForkJoinPool;

public class JavaForkJoinPoolExample {
  public static void main(String[] args) {
    ForkJoinPool fjp1 = ForkJoinPool.commonPool();  // factory method to create a shared Pool that entire applicaion uses
	ForkJoinPool fjp2 = new ForkJoinPool(4);  // create pool using new keyword passing the parallelism level
	
	MyRecursiveAction myRecursiveAction = new MyRecursiveAction(123);
	fjp1.invoke(myRecursiveAction);
	
	MyRecursiveTask myRecursiveTask = new MyRecursiveTask(123);
	long result = fjp1.invoke(myRecursiveTask);
	
	System.out.println(result);
	sleep(1000);
  }
}

- Note that, the RecursiveAction does not return any result, whereas RecursiveTask returns task.


import java.util.concurrent.RecursiveAction;
public class MyRecursiveAction extends RecursiveAction {
  private long workLoad = 0;
  public MyRecursiveAction(long workLoad) {  this.workload = workload;  }

  @Override
  protected void compute() {
    // if work is above threshold, break tasks in subtasks
	if(this.workload > 16) {
	  System.out.println("Splitting workload :" + this.workload);
	  long workLoad1 = this.workLoad / 2;
	  long workLoad2 = this.workLoad - workLoad1;
	  
	  MyRecursiveAction subTask1 = new MyRecursiveAction(workLoad1);
	  MyRecursiveAction subTask2 = new MyRecursiveAction(workLoad2);
	  subTask1.fork();
	  subTask2.fork();
	} else {
	  System.out.println("Doing workload myself :" + this.workLoad);
	}
  }
}



import java.util.concurrent.RecursiveTask;
public class MyRecursiveTask extends RecursiveTask<Long> {
  private long workLoad = 0;
  public MyRecursiveTask(long workLoad) {  this.workload = workload;  }

  @Override
  protected Long compute() {
    // if work is above threshold, break tasks in subtasks
	if(this.workload > 16) {
	  System.out.println("Splitting workload :" + this.workload);
	  long workLoad1 = this.workLoad / 2;
	  long workLoad2 = this.workLoad - workLoad1;
	  
	  MyRecursiveTask subTask1 = new MyRecursiveTask(workLoad1);
	  MyRecursiveTask subTask2 = new MyRecursiveTask(workLoad2);
	  subTask1.fork();
	  subTask2.fork();
	  
	  long result = 0;
	  result += subTask1.join();
	  result += subTask2.join();
	  return result;
	} else {
	  System.out.println("Doing workload myself :" + this.workLoad);
	  return workLoad * 3;
	}
  }
}

Some commonly used methods:
---------------------------
ForkJoinTask<Long> fjt = fjp1.submit(myRecursiveTask);  // similar to future
Long result = fjt.get();

fjp1.getParallelism();
fjp1.setParallelism(10);
fjp1.getPoolSize();
fjp1.getQueuedSubmissionCount();
fjp1.getRunningThreadCount();
fjp1.isShutdown();
fjp1.isTerminated();
fjp1.isTerminating();
fjp1.shutdown();
fjp1.shutdownNow();




Semaphore:
==========
- Consider we have an application with services ServiceA and ServiceB. Let us say, ServiceB usually takes more time to respond.
- If multiple thread tries to access the service, after some time, threads will have to wait for long time until current executing threads completes their turn.
- To avoid this, we can restrict only n number for threads can access the application.
- This way we can make other threads to wait or let them do some alternate task in the mean time.

- When Semaphore is defined with specified number of permits, the threads trying to perform some task, will need to acquire the permit to perform the task. Once the task is completed, the permit is released.
- Note, as and when acquire and release methods are called the available permit increases and decreases respectively.
- When the availablePermits is 0, and if any thread tries to acquire permit, it will be blocked until some other thread releases permit(s).
- It is important to note that, the number of permits a thread tries to acquire (if multiple), then same number of permits need to be released when the task is completed. Otherwise, at sometime in future, we might run out of permits.

Example:
--------
static class Task implements Runnable {
  public void run() {
    semaphore.acquire();
	// do actual task
	semaphore.release();
  }
}

public static void main(String[] args) {
  Semaphore semaphore = new Semaphore(5);
  ExecutorService service = Executors.newFixedThreadPool(50);
  Intstream.of(1000).forEach( i -> service.execute(new Task(semaphore)) );
  service.shutdown();
  service.awaitTermination(1, TimeUnit.MINUTES);
}

Commonly used methods:
----------------------
Semaphore smObj = new Semaphore(no_of_permits); // creates Semaphore object with number of permits
Semaphore smObj = new Semaphore(no_of_permits, fairness); // create Semaphore object with number of permits along with fairness boolean. Fairness guarantee for threads waiting the longest

smObj.acquire(); // thread to acquire the permit to start the execution
smObj.acquire(n);  // to acquire n number of permits at a time.

smObj.tryAcquire(); // tries to acquire, if no permit available, do not block (do something else)
smObj.tryAcquire(timeout); // Same as tryAcquire() but with timeout

smObj.release(); // thread to release the permit after the execution
smObj.release(n);  / to release multiple permits at a time

smObj.availablePermits(); // display the no of permits available
smObj.getQueueLength();  // to get the number of thread waiting in the queue to acquire permits.


CountDownLatch:
===============
- CountDownLatch is a synchronizer that allows one or more threads to wait for a set of operations to complete. 
- Imagine you are developing a server application that relies on various resources to be initialized before it can start processing requests.
- These resources could be things like:
  - Loading configuration files
  - Establishing database connections
  - Initializing caches
  - Starting embedded servers or services

- A CountDownLatch is initialized with a given count, representing the number of actions before the latch is released.
- Each action decrements this count. When the count reaches zero, all waiting threads are released, and any subsequent invocations of the latch's methods will pass without blocking.

- The primary methods are await() for waiting and countDown() for decrementing the count.

A simple example of CountDownLatch is shown below.

public class MyCountDownLatchProgram {

  public static void main(String[] args) {
    ExecutorService exService = Executors.newFixedThreadPool(5);
	
	CountDownLatch latch = new CountDownLatch(4);
	exService.submit(new DependentService(latch));
	exService.submit(new DependentService(latch));
	exService.submit(new DependentService(latch));
	exService.submit(new DependentService(latch));
	
	latch.await();
	System.out.println("All dependent services initialized");
  }
}

class DependentService implements Runnable {
  private CountDownLatch latch;
  public DependentService(CountDownLatch latch){ this.latch = latch; }
  
  public void run() {
    // startup task
    latch.countDown();
	// continue with other operations
  }
}

- If the Workers terminate with some error before calling countDown() method, the main thread will await indefinitely.
- To avoid this we can call await method with timeout mentioned, so that it return false after the timeout period.
  boolean completed = latch.await(3L, TimeUnit.SECONDS);


CyclicBarrier:
==============
- It enables multiple threads to wait for each other at a predefined execution point before resuming work.
- The significant benefit of CyclicBarrier over CountDownLatch is reusability.
- It can be reused after the waiting threads are released in its barrier point. That's why it's named 'Cyclic'.
- A simple example is shown below.

public class MyCyclicBarrierProgram {

  public static void main(String[] args) throws InterruptedException {
    ExecutorService exService = Executors.newFixedThreadPool(5);
	
	CyclicBarrier barrier = new CyclicBarrier(3);
	exService.submit(new MyTask(barrier));
	exService.submit(new MyTask(barrier));
	exService.submit(new MyTask(barrier));
	
	Thread.sleep(2000);
  }
}

class MyTask implements Runnable {
  private CyclicBarrier barrier;
  public MyTask(CyclicBarrier barrier){ this.barrier = barrier; }
  
  public void run() {
    while(true){  // condition until which the operation needs to be repeated
	  try {
	    barrier.await();
	  } catch(InterruptedException | BrokenBarrierException ex) {
	    ex.printStackTrace();
	  }
	}
  }
}


Phaser:
=======
- Phaser is another synchronization which can act as CountDownLatch and CyclicBarrier and also has additional features.

Phaser as CountDownLatch:
-------------------------
public class PhaserAsCountDownLatch {

  public static void main(String[] args) {
    ExecutorService exService = Executors.newFixedThreadPool(4);
	
	Phaser phaser = new Phaser(3);
	exService.submit(new DependentService(phaser));
	exService.submit(new DependentService(phaser));
	exService.submit(new DependentService(phaser));
	exService.submit(new DependentService(phaser));
	
	phaser.awaitAdvance(1);  // similar to latch.await();
	System.out.println("All dependent services initialized");
  }
}

class DependentService implements Runnable {
  private Phaser phaser;
  public DependentService(Phaser phaser){ this.phaser = phaser; }
  
  public void run() {
    // startup task
    phaser.arrive();  // similar to latch.countDown();
	// continue with other operations
  }
}


Phaser as CyclicBarrier:
------------------------
public class PhaserAsCyclicBarrier {

  public static void main(String[] args) throws InterruptedException {
    ExecutorService exService = Executors.newFixedThreadPool(4);
	
	Phaser phaser = new Phaser(3);
	exService.submit(new MyTask(phaser));
	exService.submit(new MyTask(phaser));
	exService.submit(new MyTask(phaser));
	
	Thread.sleep(2000);
  }
}

class MyTask implements Runnable {
  private Phaser phaser;
  public MyTask(Phaser phaser){ this.phaser = phaser; }
  
  public void run() {
    while(true){  // condition until which the operation needs to be repeated
	  phaser.arriveAndAwaitAdvance(); // similar to barrier.await()
	  // send message to corresponding system
	}
  }
}

- After barrier is broken each time, the Phaser will change as 1,2,3.. etc. 


Additional features in Phaser:
------------------------------
- Phaser allows us to register in multiple phase.
1. Phaser phaser = new Phaser(1);  // at the time of instantiation
2. phaser.register();  // allow worker thread to register themselves
3. phaser.bulkRegister(4);  // to increase my of parties registered at any point of time.

- Deregister to make thread to be not part of operation anymore.
  phaser.arriveAndDeregister();

getPhase(): Get current phase (similar to CyclicBarrier cycle count)
getArrivedParties(): Get count of parties arrived
getUnarrivedParties(): Get count of parties not yet arrived

onAdvance(): Override method (similar to barrier action)
forceTerminate(): Terminate the phaser
isTerminated(): Check if phaser is terminated






Concepts by Defog Tech: https://www.youtube.com/playlist?list=PLhfHPmPYPPRk6yMrcbfafFGSbE2EPK_A6
-----------------------

























Fail-fast Iterator:
===================
- Immediately throws ConcurrentModificationException if there is a structural modification of the collection.
- Structural modification means adding, removing, updating any value in the collection while another thread is iterating over the collection.
- The Fail-fast iterator uses original collection to traverse collection.
- Eg: ArrayList, HashMap

Fail-safe Iterator:
===================
- Does not throw ConcurrentModificationException if there is a structural modification of the collection.
- Structural modification means adding, removing, updating any value in the collection while another thread is iterating over the collection.
- The Fail-safe iterator uses a copy of original collection to traverse over the elements.
- In Java, there is nothing called Fail safe. In fact, it means non-Fail fast.
- Eg: CopyOnWriteArrayList, ConcurrentHashMap


ConcurrentHashMap:
==================
- Hashmap is not thread safe.
- Hashtable is thread safe. But when used, the entire object is locked for other threads to access.
- In SynchronizedMap, when a thread modifies any segment, the entire map object is locked for modification by other threads.
- In ConcurrentHashMap, the entire object is not locked by a single lock. Instead, it divides the buckets of object into multiple segments (16 by default) and provides one lock for each section. This way different thread will acquire lock to different sections of the object, so that other sections which are not locked can be accessed by some other threads.
- ConcurrentHashMap does not lock the Map while you are reading from it. Additionally, ConcurrentHashMap does not lock the entire Map when writing to it. It only locks the part of the Map that is being written to, internally.


ConcurrentMap and ConcurrentHashMap:
====================================
Commonly used map interfaces and classes are:
- Map, Hashtable, HashMap, ConcurrentMap, ConcurrentHashMap

- Here Map is the base of all other interfaces/classes. It is not thread-safe.
- Hashtable is unordered collection. It is thread-safe. So only one thread can access one of its methods at a time.
- HashMap is not thread-safe.
- ConcurrentHashMap is thread-safe. Improvement of Hashtable. It allows multiple threads to read and write at the same time provided they are not perfromed on the same key and same bucket.


WeakHashMap:
============
- WeakHashMap is an implementation of the Map interface where its key are stored as weak references. 
- WeakHashMap is almost same as HashMap except in case of WeakHashMap, if object is specified as key doesn’t contain any references.
- It is eligible for garbage collection even though it is associated with WeakHashMap.
- HashMap implements Cloneable interface. WeakHashMap does not implement Cloneable interface, it only implements Map interface. Hence, there is no clone() method in the WeakHashMap class.

public static void main(String[] args) {

  WeakHashMap<Object, String> map = new WeakHashMap<>();
  Object key1 = new Object();
  Object key2 = new Object();
  
  map.put(key1, "Value of key1");
  map.put(key2, "Value of key2");
  System.out.println("Map size: " + map.size());  // prints 2
  
  key1 = null;
  System.out.println("Map size after nullifying: " + map.size());  // prints 2
  
  System.gc();
  try {
    Thread.sleep(2000);
  } catch(Exception ex) {  ex.getMessage();  }
  System.out.println("Map size after GC run: " + map.size());  // prints 1. In case of HashMap still prints 2
}






CopyOnWrite Collections:
========================
A thread-safe variant of ArrayList in which all mutative operations like add, set etc., are implemented by making a fresh copy of the underlying array.
This is costly, but may be more efficient when traversal operations vastly outnumber mutations.
These classes synchronize only add, put etc operations while not synchronizing get operation.



Iterable:
=========
Reference: https://youtu.be/zugG_gFrv34?list=PLL8woMHwr36HmQfxqqqxns5GexTNmxFqK


Iterator:
=========
Reference: https://youtu.be/mzpgeRuYduY?list=PLL8woMHwr36HmQfxqqqxns5GexTNmxFqK


Comparator and Comparable:
==========================

Java Techie: https://www.youtube.com/watch?v=X-LynP9sVSM
Baeldung: https://www.baeldung.com/java-comparator-comparable
Digital Ocean: https://www.digitalocean.com/community/tutorials/comparable-and-comparator-in-java-example
GeeksforGeeks: https://www.geeksforgeeks.org/comparable-vs-comparator-in-java/
Medium (by Ashutosh Krishna): https://ashutoshkrris.medium.com/comparable-vs-comparator-explained-in-java-0aabaedf8d47

Java Collections class:
=======================
Jenkov: https://jenkov.com/tutorials/java-collections/collections.html











JVM ARCHITECTURE:
=================

https://www.guru99.com/java-virtual-machine-jvm.html


Compiled Languages: In programming languages like C, C++, then code is first compiled into a platform specific machine code and thereafter the code can run only on that specific platform

Interpreted Languages: In programming languages like Python, Javascript, the instructions are executed directly without having to compile them.

JAVA uses the combination of above two. Code (.java) is first compiled into bytecode to generate class file (.class). This class file is then interpreted by JVM for the underlying platform. The same class file can be run in different platform using their respective JVM.


JVM Architecture structure:
---------------------------
JVM
  |
  +-- Class Loader
  |     |
  |     +-- Loading
  |     |     |
  |     |     +-- Bootstrap Class Loader
  |     |     +-- Extension Class Loader
  |     |     +-- Application Class Loader
  |     |
  |     +-- Linking
  |     |     |
  |     |     +-- Verification
  |     |     +-- Preparation
  |     |     +-- Resolution
  |     |
  |     +-- Initialization
  |
  +-- Runtime Memory/Data Area
  |     |
  |     +-- Method Area
  |     +-- Heap Area
  |     +-- Stack Area
  |     +-- PC Register
  |     +-- Native Method Stack
  |
  +-- Execution Engine
        |
        +-- Interpreter
        +-- JIT(Just In Time) Compiler
        |     |
        |     +-- Intermediate Code Generator
        |     +-- Code Optimizer
        |     +-- Target Code Generator
        |     +-- Profiler
        |         
        +-- Garbage Collector
              |
              +-- Serial
              +-- Parallel
              +-- G1







Class Loader: Prepares the Java classes and loads them into main memory.

Runtime Memory/Data Area: Holds the runtime variables and data.

Execution Engine: Looks for the main method and executes the program.


Class Loader:
-------------
Loading:
--------
It involves taking the binary representation/bytecode of class or interface and generating the original class/interface from that.
Three types of class loader available in JVM are:
Bootstrap Class Loader:
  Root class loader
  Loads the standard java packages like java.lang, java.util, java.net, java.io, etc.
  These packages are present inside rt.jar file inside JRE/lib directory.

Extension Class Loader:
  Sub class of Bootstrap Class Loader.
  Loads files present inside JRE/lib/ext directory.

Application Class Loader:
  Sub class of Extension Class Loader.
  Loads files present in the classpath.
  By default, the classpath is set to current directory which can be overridden using -cp or -classpath option in CLI


Linking:
--------
Process of combining the elements and dependencies together
It goes through following steps:
Verification:
  This phase checks the structural correctness of the .class file by checking it against a set of rules or constraints.
  For example if a class is written using Java 11 features and run using Java 8, then VerifyException will be thrown.

Preparation:
  In this phase, the JVM allocates memory for the static fields of a class or interface and initializes it with default values.

Resolution:
  In this phase, the symbolic references are replaced with direct references present in the runtime constant pool.
  For example, the references to other classes and constants.


Initialization:
---------------
This phase involves executing the initialization method of the class or interface.
For example, calling class's constructor, executing the static blocks and assign actual values to all static variables (which was initialized with default value in preparation phase).
This is the final stage of class loading.


Runtime Memory/Data Area:
-------------------------
Method Area:
------------
All the class level data such as run-time constant pool, fields and method data and the code for methods and constructors.
If the memory available in the method area is not sufficient for the program startup, the JVM throws OutOfMemoryError.
There is only one Method Area per JVM.

Heap Area:
----------
All the objects and corresponding instance variables and arrays are stored here.
This is the run-time data area from which memory for all class instances and arrays is allocated.
There is only one Heap Area per JVM.

Stack Area:
-----------
All local variables, methods and partial results are stored here.
For every method call, one entry is made in the stack memory which is called as Stack Frame. When the method call is complete, the Stack Frame is destroyed.
Stack Frame is further divided in 3 parts namely
  - Local Variables
  - Operant Stack
  - Frame Data


PC Register:
------------
JVM supports multiple threads at the same time.
Each thread has its own PC Register to hold the address of the currently executing JVM instruction.
Once the instruction is executed, the PC Register is updated with the next instruction.

Native Method Stack:
--------------------
JVM contains stacks that support native methods which are written in languages other than Java like C, C++.
For every thread created, a seperate native method stack is allocated.


Execution Engine:
=================
Once the bytecode is loaded into main memory, it needs to be executed which is handled by Execution Engine.
However, the bycode needs to be converted into machine language using an Interpreter or Just In Time Compiler.

Interpreter:
------------
Reads the bytecode line by line. So it is slower.
Also, when a method is called multiple times, it needs to be interpreted every time.

JIT Compiler:
-------------
JVM first uses interpreter to execute the bytecode, but when it finds repeated code it uses JIT Compiler to convert it into native code.
JIT Compiler is divided into 3 parts:
- Intermediate Code Generator: Generates the intermediate code.
- Code Optimizer: Optimizes the code for better performance.
- Target Code Generator: Coverts the optimized code into native machine code.
- Profiler: Identifies the hotspot(frequently executing code) in the code.

Garbage Collector:
------------------
The GC collects and removes unreferenced objects.
It is the process of reclaiming the used memory automatically by JVM.
It has 2 phases: Mark (marks the object for GC) and Sweep (clears the memory).
There are 3 types of GC:
Serial: For small application running on single thread environment. So when this GC runs, the entire application is paused. 
Parallel: The default GC, uses multi thread environment. This also pauses application, when it is run.
G1: It divides the memory into partitions and the partition which has more garbage resources is cleared first.


Java Native Interface:
======================
Somtimes code needs to be written in language other than Java for interacting with hardware components etc.
JNI acts as a bridge for that purpose.




Garbage Collection:
===================
https://www.baeldung.com/jvm-garbage-collectors
https://www.youtube.com/watch?v=XXOaCV5xm9s
https://www.youtube.com/watch?v=2AZ0KKeXJSo



https://anmolsehgal.medium.com/java-garbage-collectors-610689a5b125#:~:text=ZGC%3A%20Designed%20for%20applications%20requiring,collection%20concurrently%20with%20the%20application.



Serial GC:
==========
single-threaded GC suitable for small applications or systems with low memory requirements.
It pauses the application’s execution(stop-the-world) during garbage collection.
Works with Mark-Sweep-Compact concept. Marks used objects, then Sweeps unused objects and finally compacts the memory by moving live objects together.

Pros:
-----
Simplicity: straightforward to implement and understand.
Low Overhead: lower CPU and memory overhead compared to more complex GC algorithms
Predictable Pauses: provides predictable pauses allowing for better control over the application behavior.
Single-threaded Execution: performs garbage collection using a single thread which aviods potential multi-threading issues.

Cons:
-----
Longer Pause Times
Limited Scalability
Not Suitable for Large Applications: its performance may degrade due to increased GC times for large applications.


Parallel GC:
============
Uses multi-core processors and provides improved GC performance by parallelizing certain tasks.
It pauses the application’s execution(stop-the-world) during garbage collection.
Works with Mark-Sweep-Compact concept. Marks used objects, then Sweeps unused objects and finally compacts the memory by moving live objects together. While performing these opertions the GC uses seperate thread thereby resulting in higher throughput.

Pros:
-----
Improved Throughput: by using multiple threads to execute GC tasks concurrently.
Reduced Pause Times: By parallelizing the marking, sweeping, and compaction phases.
Scalability
Enhanced Performance: Compared to Serial GC.

Cons:
-----
Increased CPU Utilization: Using multiple threads, leads to higher CPU utilization which may affect the overall system performance for applications with limited CPU resources.
Longer Individual Pause Times: While the overall pause time may be reduced, the individual pause times for each garbage collection cycle might be longer compared to other algorithms.
Not Suitable for Small Systems(with limited resources or single-core processors).



CMS (Concurrent Mark-Sweep) GC:
===============================
A low-latency garbage collection 
Performs most of the GC work concurrently with the application’s execution.

Pros:
-----
Reduced Pause Times
Improved Scalability
Effective for Mixed Workloads: CMS performs well where the application generates a significant amount of short-lived objects.

Cons:
-----
Increased CPU Utilization: due to the additional threads involved in garbage collection.
Fragmentation Concerns: CMS may suffer from memory fragmentation issues, leading to less efficient memory utilization.
Limited Pause Reduction: While CMS reduces pauses compared to other algorithms, it may not eliminate pauses entirely, and long-running concurrent phases can still impact application performance.
Deprecated in Java 9+: Deprecated in Java 9 and later versions, with the intention to be removed in future releases. The introduction of the Garbage-First (G1) GC aims to provide a more efficient and scalable alternative.



G1 (Garbage-First) GC:
======================
The G1 GC is a parallel and concurrent garbage collector that divides the heap into multiple regions. 
It operates based on the concept of regions, where each region is a fixed-size block of memory. 
The heap is dynamically divided into Eden regions, survivor regions, and old regions. 
The G1 GC collects garbage in a region-based manner, allowing it to prioritize the most heavily garbage-filled regions first.

Pros:
-----
Improved Pause Times: G1 GC aims to provide more predictable and shorter pause times, especially for applications with large heaps, by minimizing the duration of stop-the-world garbage collection pauses.
Adaptive Behavior: G1 GC adjusts its heap partitioning and collection strategies based on the application’s workload, allowing it to dynamically adapt to changing memory usage patterns.
Better Utilization of Hardware Resources: G1 GC utilizes multiple threads for parallel garbage collection, which can lead to better utilization of available CPU resources, resulting in improved application throughput.
Reduced Fragmentation: G1 GC’s compacting algorithm reduces memory fragmentation by reclaiming memory from regions with a high garbage-to-live object ratio.

Cons:
-----
Increased Overhead: Compared to other garbage collectors, G1 GC may introduce a slightly higher CPU overhead due to its more complex heap management and concurrent marking algorithms.
Longer Application Warm-Up: G1 GC may exhibit longer warm-up times as it gathers statistics and adapts its behavior to optimize garbage collection performance.


Z Garbage Collector:
====================
A modern, low-latency garbage collector designed to handle large heaps with minimal pauses. 
Introduced in JDK 11, ZGC aims to provide excellent responsiveness and scalability for applications with large memory requirements.


Shenandoah GC:
==============
A GC designed for a low-pause time in Java applications. 
It is an open-source garbage collector that aims to reduce the impact of garbage collection on application responsiveness. Shenandoah GC is available as an experimental feature in OpenJDK 8 and 11 and as a production feature starting from OpenJDK 12.


Epsilon GC:
===========
Epsilon GC is a special-purpose garbage collector introduced in JDK 11. It is designed for specific use cases where garbage collection is not required or can be completely eliminated. Epsilon GC is an experimental feature that serves as a 'no-op' garbage collector, meaning it does not perform any garbage collection activities. It is primarily used for performance testing, short-lived applications, or situations where the application manages memory explicitly.


Azul C4 GC:
===========
Designed for high-performance and low-latency requirements, C4 GC utilizes pauseless, concurrent collection techniques.


IBM Metronome GC:
=================
An experimental real-time GC algorithm that focuses on predictable and consistent pause times.



SAP Garbage Collector:
======================
A concurrent GC algorithm optimized for large heap sizes and low-latency requirements.



Comparison:
https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pejtNmOlvm5JYr25QJhKoA.png







Method References:
==================
Introduction:
-------------
We use lambda expressions to create anonymous methods. Sometimes, a lambda expression does nothing but call an existing method.
In those cases, it's often clearer to refer to the existing method by name. Method references enable you to do this.


Types of Method References:
---------------------------
1. Reference to a static method:
--------------------------------
Syntax:
  ContainingClass::staticMethodName	
Example:
  Person::compareByAge
  MethodReferencesExamples::appendStrings


2. Reference to an instance method of a particular object:
----------------------------------------------------------
Syntax:
  containingObject::instanceMethodName
Example:
  myComparisonProvider::compareByName
  myApp::appendStrings2


3. Reference to an instance method of an arbitrary object of a particular type:
-------------------------------------------------------------------------------
Syntax:
  ContainingType::methodName
Example:
  String::compareToIgnoreCase
  String::concat


4. Reference to a constructor:
------------------------------
Syntax:
  ClassName::new
Example:
  HashSet::new


Consider a Person class.

public class Person {
  int age;
  LocalDate birthday;
  
  public int getAge() { ... }
  public LocalDate getBirthday() { return birthday; }   

  public static int compareByAge(Person a, Person b) {
    return a.birthday.compareTo(b.birthday);
  }
}


public class MethodReferencesTest {
  // The method transferElements copies elements from one collection to another

  public static <T, SOURCE extends Collection<T>, DEST extends Collection<T>> DEST transferElements(
      SOURCE sourceCollection, Supplier<DEST> collectionFactory) {

    DEST result = collectionFactory.get();
    for (T t : sourceCollection) {  result.add(t);  }
      return result;
  }

  public static void main(String... args) {
    List<Person> roster = Person.createRoster();
    for (Person p : roster) { p.printPerson(); }
    Person[] rosterAsArray = roster.toArray(new Person[roster.size()]);

    class PersonAgeComparator implements Comparator<Person> {
      public int compare(Person a, Person b) {  return a.getBirthday().compareTo(b.getBirthday());  }
    }

    // Without method reference
    Arrays.sort(rosterAsArray, new PersonAgeComparator());

    // With lambda expression
    Arrays.sort(rosterAsArray, (Person a, Person b) -> {
        return a.getBirthday().compareTo(b.getBirthday());
      }
    );

    // 1. Reference to a static method
    Arrays.sort(rosterAsArray, Person::compareByAge);

    // 2. Reference to an instance method of a particular object
    class ComparisonProvider {
      public int compareByName(Person a, Person b) {  return a.getName().compareTo(b.getName());  }
      public int compareByAge(Person a, Person b) {  return a.getBirthday().compareTo(b.getBirthday());  }
    }
    ComparisonProvider myComparisonProvider = new ComparisonProvider();
    Arrays.sort(rosterAsArray, myComparisonProvider::compareByName);


    // 3. Reference to an instance method of an arbitrary object of a particular type
    String[] stringArray = { "Barbara", "James", "Mary", "John", "Patricia", "Robert" };
    Arrays.sort(stringArray, String::compareToIgnoreCase);
    Set<Person> rosterSetLambda = transferElements( roster, () -> {  return new HashSet<>();  } );


    // 4. Reference to a constructor
    Set<Person> rosterSet = transferElements(roster, HashSet::new);
    System.out.println("Printing rosterSet:");
    rosterSet.stream().forEach(p -> p.printPerson());
    }
}



Java is 'Pass By Value':
========================
Java is always pass by value. 
In Java, there are 2 types of variables/values. Primitive values and Objects.

Example 1:
----------
public class Main {

  public static void main(String[] args) {
    int a = 5;
	int b = a;
	doSomething(b);
	System.out.printf("%d, %d", a, b);
  }
  
  public static void doSomething(int temp) {
  temp = 10;
  }
}

output: 5, 5
Since a copy of value b is passed to method doSomething() and the temp variable's scope is within the method, the original value is not changed.


Example 2:
----------
public class Main {

  public static void main(String[] args) {
    int a = 5;
	int b = a;
	b = doSomething(b);
	System.out.printf("%d, %d", a, b);
  }
  
  public static int doSomething(int temp) {
  temp = 10;
  return temp;
  }
}

output: 5, 10

In this case, we are returning the temp value from the method and reassigning it to b.


Example 3:
----------
public class CustomObject {
  private int data;
  public CustomObject(int data) {  this.data = data;  }
  public void printInfo() {  System.out.println("Custom object data : " + data);  }
  public void setData(int data){  this.data = data;  }
}

public class Main {

  public static void main(String[] args) {
    CustomObject a = new CustomObject(5);
	CustomObject b = a;
	doSomething(b);
	a.printInfo();
	b.printInfo();
  }
  
  public static void doSomething(CustomObject temp) {
    temp.setData(10);
  }
}

output: 
Custom object data : 10
Custom object data : 10

Here we are passing a reference to doSomething() method. Though they are different reference variables, the actual object to which it points to is one and the same. So the value gets modified.


Example 4:
----------
public class CustomObject {
  private int data;
  public CustomObject(int data) {  this.data = data;  }
  public void printInfo() {  System.out.println("Custom object data : " + data);  }
  public void setData(int data){  this.data = data;  }
}

public class Main {

  public static void main(String[] args) {
    CustomObject a = new CustomObject(5);
	CustomObject b = a;
	doSomething(b);
	a.printInfo();
	b.printInfo();
  }
  
  public static void doSomething(CustomObject temp) {
    temp = new CustomObject(10);
  }
}

output: 
Custom object data : 5
Custom object data : 5

Here we are assigning a new object to temp variable. 
The existing variables a and b point to the original object UNCHANGED.




StringJoiner class:
===================
It joins String separated by a delimiter, starting with a supplied prefix and ending with a supplied suffix.
The static method join of String internally uses StringJoiner.

Examples:
---------
public static void main(String[] args) {
  // 1. Join Strings using only delimiter
  StringJoiner joiner = new StringJoiner(",");
  joiner.add("John");
  joiner.add("Peter");
  joiner.add("Alex");
  System.out.println(joiner);  // John,Peter,Alex
  
  // 2. Join Strings using delimiter, prefix and suffix
  StringJoiner joiner = new StringJoiner(",", "{", "}");
  joiner.add("John");
  joiner.add("Peter");
  joiner.add("Alex");
  System.out.println(joiner);  // {John,Peter,Alex}
  
  // 3. Merging two joners
  StringJoiner joiner1 = new StringJoiner(",", "{", "}");
  StringJoiner joiner2 = new StringJoiner(",", "[", "]");
  joiner1.add("John");
  joiner1.add("Peter");
  joiner1.add("Alex");
  joiner2.add("Kandhan");
  joiner2.add("Kumaran");
  joiner2.add("Murugan");
  System.out.println(joiner1.merge(joiner2));  // {John,Peter,Alex,Kandhan,Kumaran,Murugan}
  System.out.println(joiner2.merge(joiner1));  // [Kandhan,Kumaran,Murugan,John,Peter,Alex,Kandhan,Kumaran,Murugan]
  
  // 4. Using Collectors.joining
  List<String> list = Arrays.asList("John","Peter","Alex");
  System.out.println(list.stream().collect(Collectors.joining("-")));  // John-Peter-Alex
  System.out.println(list.stream().collect(Collectors.joining("-", "(", ")")));  // (John-Peter-Alex)
  
  // 5. Using String.join()
  List<String> list = Arrays.asList("John","Peter","Alex");
  System.out.println(String.join("^", list));  // John^Peter^Alex
}



Generics in Java:
=================
References:
Coding with John - https://www.youtube.com/watch?v=K1iu1kXkVoA
Bro Code - https://www.youtube.com/watch?v=jUcAyZ5OUm0
Geekific - https://www.youtube.com/watch?v=vqjA6dqugq8 and https://www.youtube.com/watch?v=FXAUXvPNKi8

Scenario:
---------
- Consider we have a class IntegerPrinter that contains the method print(Integer val) to print the value. 
- This class accepts only Integer parameter. If a Double value needs to printed, we need to create seperate class. Same for any other type.
- However, with generics we can have single class that takes generic type to print any type of value.

class Printer<T> {
  T thingToPrint;

  public Printer(T thingToPrint) {
    this.thingToPrint = thingToPrint;
  }
  public void print() {
    System.out.println(this.thingToPrint);
  }
}

public class GenericExample1 {
  public static void main (String[] args) {
    Printer<Integer> integerPrinter = new Printer<>(20);
	integerPrinter.print();
	
	Printer<Double> doublePrinter = new Printer<>(30.4);
	doublePrinter.print();
  }
}


Scenario 2:
-----------
- In the above scenario, Printer class literally accepts any type. However we can restrict to accept few types (like all class under particular hierarchy).
- So if any class that does not extend Animal is passed, it will result in compilation error.
- Also, we can use any methods that is defined in Animal class.

class Printer<T extends Animal> {
  T thingToPrint;

  public Printer(T thingToPrint) {
    this.thingToPrint = thingToPrint;
  }
  public void print() {
    thingToPrint.eat();
    System.out.println(this.thingToPrint);
  }
}


Scanario 3:
-----------
We can also use generics at method level so that, it can accept any type and print.

public class GenericExample1 {
  
  public static <T> void print(T thingToPrint){
    System.out.println(thingToPrint);
  }
  
  public static void main (String[] args) {
    print(25);
    print("Hello Generics");
    print(new Cat());
  }
}


Scanario 4:
-----------
We can also use generics as return type in addition to method parameter.

  public static <T> R print(T thingToPrint, R thingToReturn){
    System.out.println(thingToPrint);

	thingToReturn = thingToPrint + "!!"	
	return thingToReturn;
  }


WildCards:
----------
- ? means anything. So we can use this wildcard to tell that the method can accept anything which is not known.

Eg 1:
-----
  public static void print(List<?> myList) {
    System.out.println(myList);
  }
  
  public static void main (String[] args) {
    List<Integer> intList = new ArrayList<>();
	intList.add(3);
	printList(intList);
	
    List<Cat> catList = new ArrayList<>();
	catList.add(new Cat());
	printList(catList);	
  }

Eg 2:
-----
  public static void print(List<? extends Animal> myList) {
    System.out.println(myList);
  }
  
  public static void main (String[] args) {
    List<Integer> intList = new ArrayList<>();
	intList.add(3);
	printList(intList);  // compilation error as Integer is not subtype of Animal
	
    List<Cat> catList = new ArrayList<>();
	catList.add(new Cat());
	printList(catList);	
  }


Examples:
----------
1. Consider a list of Cat object. If we try to add an incompatible data, we will get compilation error. This makes your code type safe.
  List<Cat> list = new ArrayList<>();
  list.add(new Cat());
  list.add(new Dog());  // Compilation error


2. If we make the above list of type Object, we can add any type which compiles file. But it fails at runtime as it might be an issue in the future.
  List<Object> list = new ArrayList<>();
  list.add(new Cat());
  Cat c1 = (Cat)list.get(0);  // typecast is required

  list.add(new Dog());
  Cat c2 = (Cat)list.get(1);  // runtime exception: Cannot cast Dog to Cat.



Exception Handling in Java:
===========================

Introduction:
-------------
An Exception is an abnormal condition or an event that disrupts the normal flow of the program.
It is an object which is thrown at runtime.

The java.lang.Throwable class is the root class of all exceptions 
Exception and Error are two subclasses.
Exceptions should be handled and Errors cannot be handled.

Types of Exceptions:
--------------------
There are three types of exceptions namely:
 - Checked Exception:
   - Classes that directly inherit Throwable class except RuntimeException and Error. 
   - Eg: IOException, SQLException, etc. 
   - Checked exceptions are checked at compile-time and these exception MUST be handled.
   - It can be handled using try-catch block or using throws keyword.
 - Unchecked Exception:
   - Classes that inherit the RuntimeException. 
   - Eg: ArithmeticException, NullPointerException, ArrayIndexOutOfBoundsException, etc. 
   - Unchecked exceptions are not checked at compile-time, but they are checked at runtime.
 - Error:
   - Error is irrecoverable. 
   - Some example of errors are OutOfMemoryError, VirtualMachineError, AssertionError etc.

Throwable
  +
  +--Exception
  +    +
  +	   +--ClassNotFoundException
  +	   +--SQLException
  +	   +--IOException
  +	   +--RuntimeException
  +	        +
  +	        +--ArithmeticException
  +	        +--NullPointerException
  +	        +--NumberFormatException
  +	        +--IndexOutOfBoundException
  +			     +
  +				 +--ArrayIndexOutOfBoundException
  +				 +--StringIndexOutOfBoundException
  +--Error
	  +
      +--StackOverflowError
      +--VirtualMachineError
      +--OutOfMemoryError


Try-catch block:
----------------
Java try block is used to enclose the code that might throw an exception.
If an exception occurs, the rest of the code in try block will not execute.
Try block must always be followed by either catch or finally block.

Catch block is used to handle the Exception (exception must be parent exception (i.e., Exception) or generated exception)
The catch block must be used after the try block only. 
You can use multiple catch block with a single try block.


Multi-catch block (Catch Multiple Exceptions):
----------------------------------------------
A try block can be followed by one or more catch blocks. 
Each catch block must contain a different exception handler.
At a time only one exception occurs and at a time only one catch block is executed.
All catch blocks must be ordered from most specific to most general, i.e. ArithmeticException must come before base class Exception.


Nested try block:
-----------------
In Java, using a try block inside another try block is permitted. It is called as nested try block.
When any try block does not have a catch block for a particular exception, then the catch block of the outer try block are checked for that exception, and if it matches, the catch block of outer try block is executed.
If none of the catch block specified in the code is unable to handle the exception, then the Java runtime system will handle the exception.


finally block:
--------------
Java finally block is always executed whether an exception is handled or not. 
So, it contains all the necessary statements like closing the resources.
The finally block follows the try-catch block.


Try-with-resources:
-------------------
- The declared resources to be used in a try block will be closed after the execution of that block. This is possible because FileInputStream implements the Java interface java.lang.AutoCloseable. So, all classes implementing this interface can be used inside the try-with-resources construct.
Eg:
  try (PrintWriter writer = new PrintWriter(new File("test.txt"))) {
    writer.println("Hello World");
  }

- We can declare multiple resources in try-with-resources block by separating them with a semicolon.
- The resources declared will be closed in reverse order of the order in which they are created / listed inside the parentheses.

- A try-with-resources block can still have the catch and finally blocks, which will work in the same way as with a traditional try-catch block.

- As of Java 9, we can now use final or even effectively final variables inside a try-with-resources block. 
- A variable is effectively final if it doesn’t change after the first assignment, even though it’s not explicitly marked as final.
  final Scanner scanner = new Scanner(new File("testRead.txt"));
  PrintWriter writer = new PrintWriter(new File("testWrite.txt"))
  try (scanner;writer) { 
    // omitted
  }


Throw keyword:
--------------
The throw keyword is used to throw an exception explicitly.
We specify the exception object which is to be thrown with some message that provides the error description.
We can throw either checked or unchecked exceptions by using throw keyword. 
It is mainly used to throw a custom exception.
We can also define our own set of conditions and throw an exception.
Syntax:
  throw new exception_class("error message");
Example:
  throw new IOException("sorry device error");

If we throw checked exception from a method, it is must to handle the exception or declare in throws clause.


Throws keyword:
---------------
The Java throws keyword is used to declare an exception.
Only Checked exception should be declared using throws keyword, because:
  unchecked exception is under our control so we can correct our code. Eg: NullPointerException.
  error: beyond our control and unable to do anything if there occurs. Eg: VirtualMachineError, StackOverflowError.

Using throws, Checked Exception can be propagated (override default behaviour).
If we are calling a method that declares an exception, we must either catch it or declare it.


Exception Propagation:
----------------------
An exception is first thrown from the top of the stack and if it is not caught, it drops down the call stack to the previous method. If not caught there, the exception again drops down to the previous method, and so on until they are caught or until they reach the very bottom of the call stack. This is called exception propagation.

By default Unchecked Exceptions are forwarded in calling chain (propagated).
By default, Checked Exceptions are not forwarded in calling chain (not propagated).


Exception Handling + Method Overriding:
---------------------------------------
If the superclass method does not declare an exception, subclass overridden method cannot declare the checked exception but it can declare unchecked exception.
If the superclass method declares an exception, subclass overridden method can declare same, subclass exception or no exception but cannot declare parent exception.


Creating custom exception:
--------------------------
In Java, we can create our own exceptions that are derived classes of the Exception class. 
Basically, custom exceptions are used to customize the exception according to business need.

In order to create custom exception, 
  1. extend Exception class that belongs to java.lang package.
  2. write a constructor that takes the String(error message) as argument and call super(errorMessage).

Eg:
class InvalidAgeException  extends Exception {  // creating custom exception by extending Exception
  public InvalidAgeException (String str) {  // creating constructor
    super(str);  // calling the constructor of parent Exception
  }
}
    

public class TestCustomException1 {  // class that uses custom exception InvalidAgeException
  static void validate (int age) throws InvalidAgeException{  // method to check the age
    if(age < 18){
      throw new InvalidAgeException("age is not valid to vote");  // throw an object of user defined exception
    }
    else {
      System.out.println("welcome to vote");
    }
  }
  
  public static void main(String args[]) {
    try {
      validate(13);
    }
    catch (InvalidAgeException ex) {
      System.out.println("Caught the exception");
      System.out.println("Exception occured: " + ex);  // printing the message from InvalidAgeException object
    }
    System.out.println("rest of the code...");
  }
}



Equals and Hashcode methods:
============================

- equals() and hashCode() are present in Object class
- Every java class gets the default implementation of equals() and hashCode()


HashMap contains an array of Node and Node can represent a class having the following objects: 
  - hash
  - key
  - value
  - next


Hashing:
--------
It is a process of converting an object into integer form by using the method hashCode(). 
It’s necessary to write the hashCode() method properly for better performance of HashMap.
More unique the hash value for different objects, better is the performance.


hashCode() method:
------------------
It is used to get the hash code of an object. 
Definition of hashCode() method is public native hashCode(). 
It indicates the implementation of hashCode() is native because there is not any direct method in java to fetch the reference of the object.
In HashMap, hashCode() is used to calculate the bucket and therefore calculate the index.
The contract for hashCode() method is:
  - internal consistency: the value of hashCode() may only change if a property that is in equals() changes
  - equals consistency: objects that are equal to each other must return the same hashCode
  - collisions: unequal objects may have the same hashCode


equals() method:
----------------
This method, available in Object class, is used to check whether 2 objects are equal or not. 
You can override this in your class to provide your implementation.
HashMap uses equals() to compare the key to check whether they are equal or not. 
If the equals() method return true, they are equal otherwise not equal.
The contract for equals() method is:
  - reflexive: an object must equal itself
  - symmetric: x.equals(y) must return the same result as y.equals(x)
  - transitive: if x.equals(y) and y.equals(z), then also x.equals(z)
  - consistent: the value of equals() should change only if a property that is contained in equals() changes



Internal working of HashMap:
============================

Buckets:
--------
A bucket is an element of the HashMap array. It is used to store nodes. 
Two or more nodes can have the same bucket. In that case, a linked list structure is used to connect the nodes. 
Buckets are different in capacity. A relation between bucket and capacity is: [capacity = number of buckets * load factor]]
A single bucket can have more than one node, it depends on the hashCode() method. 
The better your hashCode() method is, the better your buckets will be utilized.


Index Calculation in Hashmap:
-----------------------------
The Hash code of the key may be large enough to create an array. hash code generated may be in the range of integer and if we create arrays for such a range, then it will easily cause outOfMemoryException. So we generate an index to minimize the size of the array.
  - index = hashCode(key) & (n-1).
    where n is the number of buckets or the size of the array. 
	In our example, I will consider n as the default size which is 16.


Inserting Objects (put() method):
---------------------------------
Initially Empty hashMap: Here, the hashmap’s size is taken as 16.
1. Put the first element
2. Calculate hash code of Key. Consider it is 118.
3. Calculate index by using index formula. Consider it is 6.
4. Place this object at index 6, if no other object is presented there.
5. Put the subsequent elements. If the index is not same as any of the existing element, follow step 2 to 4.
6. If the index is same, it is called hashing collision.
7. In that case, check via the equals() method if both the keys are the same.
8. If keys are the same, replace the value with the current value.
9. Otherwise, connect this node object to the previous node object via linked list and both are stored at index 6.


Retrieving an element (get() method):
-------------------------------------
get(K key) method is used to get a value by its key.
1. Calculate hash code of Key.
2. Calculate index by using index formula and hash code calculated in previous step.
3. Go to appropriate index of the array and compare the first element’s key with the given key. 
4. If both are equal then return the value, otherwise, check for the next elements if it exists.



Internal working of Set/HashSet (How it stops duplicate from getting added):
============================================================================
// predefined HashSet class
public class HashSet {
  private transient HashMap map;  // A HashMap object
  private static final Object PRESENT = new Object();  // A Dummy value(PRESENT) to associate with an Object in the Map
  
  public HashSet() {  // HashSet's default constructor class creates HashMap by calling HashMap's default constructor
    map = new HashMap<>();
  }

  public boolean add(E e) { // HashSet's add method calls put() method on map object and compares it's return value with null
    return map.put(e, PRESENT)==null;
  }
}

We can see that 
1. whenever we create a HashSet, it internally creates a HashMap 
2. if we insert an element into this HashSet using add() method, it actually calls put() method on internally created HashMap object with element you have specified as it’s key and constant Object called “PRESENT” as it’s value. So we can say that a Set achieves uniqueness internally through HashMap.

Also, in a HashMap each key is unique and when we call put(Key, Value) method, it returns the previous value associated with key, or null if there was no mapping for key. So in add() method we check the return value of map.put(key, value) method with null value.
  - If map.put(key, value) returns null, then the statement “map.put(e, PRESENT) == null” will return true and element is added to the HashSet(internally HashMap).
  - If map.put(key, value) returns old value of the key, then the statement “map.put(e, PRESENT) == null” will return false and element is not added to the HashSet(internally HashMap).



Immutable classes in Java:
==========================
Rules to make a class Immutable:
1. Mark the class final
2. Mark all fields (including mutable fields) private and final
3. Do not provide setter methods
4. Initialize all fields using a constructor performing deep copy
5. Perform cloning of mutable objects in the getter methods to return a copy rather than the actual object reference


public final class Student {
  private final int regNo;
  private final String name;
  private final Date dateOfJoining;
  private final Map<String, List<String>> favs;
  private final Address address;
	  
  public Student(int regNo, String name, Date dateOfJoining, 
      Map<String, List<String>> favs, Address addr) {
	this.regNo = regNo;
	this.name = name;
	this.dateOfJoining = new Date(dateOfJoining.getTime());
	this.favs = favs.entrySet().stream()
	    .collect(Collectors.toMap(obj -> obj.getKey(), obj -> obj.getValue()));
	this.address = (Address) addr.clone();
	}

	public int getRegNo() { return regNo; }
	public String getName() { return name; }
	public Date getDateOfJoining() { new Date(dateOfJoining.getTime()); }
	public Map<String, List<String>> getFavs() { return favs.clone(); }
	public Address getAddress() { return address.clone(); }
}


Values conversions:
===================

List to Array:
	String[] arr = list.toArray(new String[0]);
	String[] arr = list.stream().toArray(String[] ::new);

Array to List:
	List<Integer> targetList = Arrays.asList(sourceArray);

String to Char array:
	char[] ch = str.toCharArray();

Char array to String:
	String string = String.valueOf(chArr);

Array to String:
	String strOutput = Arrays.toString(strArray);



int to Integer:
	Integer val1 = Integer.valueOf(int);

int to String:
	String str1 = String.valueOf(int);


Integer to int:
	int val2 = integerVal.intValue();



Why Strings are immutable in Java:
==================================
Immutability means its value cannot and does not change.
For instance, in the example shown below, a value "Hello" is first created in String pool and referenced by the variable s1. Then in the second assignment, a new String literal "Hello there" is created in the String pool and referenced by s1 now. The previous value "Hello" is lost and would be collected by garbage collector sometime later.

String s1 = "Hello";
s1 = s1 + " there";

This means the actual value was not updated. They dont change.

Reasons why Strings are immutable:
----------------------------------
1. It helps JVM to save memory space:
   - Consider a number of variables are assigned with the same value. 
   - If the concept of reusing the values in String Pool does not exist, JVM would have had to create separate value for each of the variables. Otherwise if the value is changed, all the references will have to point to the memory where new value is stored.
   - However, it it to be noted that, if another string is created with same value, but using new keyword, it will not use the existing object, instead create a new object/value outside the String Pool. This happens everytime the new keyword is used.

2. It is to ensure security:
    - Consider a case where a method makePayment() takes account holder name as an argument.
	- If an unauthorized user creates a new variable pointing to the actual existing value and if the values is changed, then the actual variable will change (point to new value).


3. Strings are thread safe:
    - No matter how many number of threads access a string value in the String pool, none of them can change/update the value. Instead of modifying the existing value, a new String would be created in the String pool.

4. Hashcode Caching:
    - When operating upon these hash implementation for data structures like HashMap, HashTable, HashSet, etc, hashCode() method is called quite frequently for bucketing.
	- Mutable Strings would produce two different hashcodes at the time of insertion and retrieval if contents of String was modified after the operation, potentially losing the value object in the Map.



MapStruct (Java Bean mapper):
=============================
Reference:
https://www.baeldung.com/mapstruct
https://madukajayawardana.medium.com/maximizing-java-code-efficiency-and-clarity-with-mapstruct-a-comprehensive-guide-be3a498c6d74





















































Default and Static Methods in Interfaces:
=========================================
https://javagyansite.com/2020/01/27/interface-default-and-static-methods/


Method References:
==================
https://gbmishra.medium.com/a-comprehensive-guide-to-java-8-features-and-benefits-2cd8a2ee8dd3


Lambda Expressions:
===================
https://javagyansite.com/2020/01/27/lambda-expression-in-java-8/


Stream API:
===========
https://javagyansite.com//2018/09/30/java-8-stream/
https://javagyansite.com/2018/10/02/java-8-stream-continues/
https://javagyansite.com/2018/10/02/parallel-streams-in-java-8/
https://javagyansite.com/2020/02/05/stream-more-apis/
https://javagyansite.com/2020/02/05/stream-terminal-and-non-terminal-operations/
https://javagyansite.com//2020/01/27/flatmap-in-stream/


Optional Class:
===============
https://javagyansite.com/2020/02/05/optional-class-in-java-8/


Default and Static Methods in Interfaces:
=========================================
https://javagyansite.com/2020/01/27/interface-default-and-static-methods/


Method References:
==================
https://gbmishra.medium.com/a-comprehensive-guide-to-java-8-features-and-benefits-2cd8a2ee8dd3



java.time Package (Date and Time API):
======================================

